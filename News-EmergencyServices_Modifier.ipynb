{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKzylmPy-2gq"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sXrahFboweh"
      },
      "source": [
        "import os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YcvfCHVHqJi"
      },
      "source": [
        "# News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVpGZsnBKiI"
      },
      "source": [
        "Snopes_harvey=pd.read_excel('/....../News/LIWC2015 Results (snopos_harvey_cleaned).xlsx')\n",
        "Snopes_irma=pd.read_excel('......./News/LIWC2015 Results (snopos_irma_cleaned).xlsx')\n",
        "CNN_harvey=pd.read_excel('......./News/LIWC2015 Results (CNN_harvey_cleaned).xlsx')\n",
        "CNN_irma=pd.read_excel('......./News/LIWC2015 Results (CNN_irma_cleaned).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIUkfS36B_nw"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def per_unit(Mental_health,minn,maxx): \n",
        "    scaler = MinMaxScaler(feature_range=(minn, maxx))\n",
        "    Mental_health=np.array(Mental_health)\n",
        "    scaler.fit(Mental_health.reshape(-1, 1))\n",
        "    Mental_health = scaler.transform(Mental_health.reshape(-1, 1))\n",
        "    return Mental_health\n",
        "CNN_irma_pos=(CNN_irma['posemo']-CNN_irma['negemo'])/CNN_irma['WC']\n",
        "min_val=0.5-(((0-CNN_irma_pos.min())*0.5)/CNN_irma_pos.max())\n",
        "CNN_irma_pos=per_unit(CNN_irma_pos,min_val,0.9999)        ##needed\n",
        "\n",
        "CNN_harvey_pos=(CNN_harvey['posemo']-CNN_harvey['negemo'])/CNN_harvey['WC']\n",
        "max_val=((CNN_harvey_pos.max()*0.5)/(0-CNN_harvey_pos.min()))+0.5\n",
        "CNN_harvey_pos=per_unit(CNN_harvey_pos,0.0001,max_val)     ##needed\n",
        "fake_harvey= per_unit(Snopes_harvey['frequency'],0,1)     ##needed\n",
        "fake_irma= per_unit(Snopes_irma['frequency'],0,1)         ##needed "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKE02XBaBGxa"
      },
      "source": [
        "# Emergency services"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6-OqJNa5Jh3"
      },
      "source": [
        "EMS_harvey=pd.read_excel('......./Emergency services/Emergency services-harvey.xlsx')\n",
        "EMS_irma=pd.read_excel('......./Emergency services/Emergency services-irma.xlsx')\n",
        "EMS_harvey=EMS_harvey.drop(['end'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKYdwq7j6bZ0"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "########### Missing Values ##############\n",
        "list_harvey=EMS_harvey.columns\n",
        "list_irma=EMS_irma.columns\n",
        "for i in  list_harvey[1:]:\n",
        "   EMS_harvey[i]=EMS_harvey[i].interpolate().astype('int32')\n",
        "\n",
        "EMS_harvey=EMS_harvey[1:]\n",
        "for i in  list_irma[1:]:\n",
        "   EMS_irma[i]=EMS_irma[i].interpolate().astype('int32')\n",
        "\n",
        "###########per unit   \n",
        "def per_unit(Mental_health): \n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    Mental_health=np.array(Mental_health)\n",
        "    scaler.fit(Mental_health.reshape(-1, 1))\n",
        "    Mental_health = scaler.transform(Mental_health.reshape(-1, 1))\n",
        "    return Mental_health\n",
        "\n",
        "for i in  list_harvey[1:]:\n",
        "   EMS_harvey[i]=per_unit(EMS_harvey[i])\n",
        "\n",
        "for i in  list_irma[1:]:\n",
        "   EMS_irma[i]=per_unit(EMS_irma[i])\n",
        "  \n",
        "EMS_harvey_mean=EMS_harvey.drop(['Time'],axis=1)\n",
        "EMS_harvey_mean=EMS_harvey_mean.mean(axis=1)  ##needed\n",
        "EMS_irma_mean=EMS_irma.drop(['Time'],axis=1)\n",
        "EMS_irma_mean=EMS_irma_mean.mean(axis=1)       ##needed\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puBoH8Aj5Elx"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKYxskvONhWj"
      },
      "source": [
        "\n",
        "**Electricity data:**\n",
        "\n",
        "https://poweroutage.us/\n",
        "\n",
        "TADS data  NERC: TADS-like public data for transamission:\n",
        "\n",
        "https://transmission.bpa.gov/Business/Operations/Outages/\n",
        "\n",
        "https://www.nerc.com/pa/RAPA/tads/Pages/default.aspx\n",
        "\n",
        "https://www.eia.gov/tools/a-z/index.php?id=I\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OurApYla0tZf"
      },
      "source": [
        "**Hurrican Irma**\n",
        "\n",
        "https://data.floridatoday.com/storm-power-outages/\n",
        "\n",
        "Power outage:  https://twitter.com/PowerOutage_us/status/911192590636240896\n",
        "\n",
        "https://www.eia.gov/special/disruptions/archive/hurricane/irma/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzOAsyZtZfqJ"
      },
      "source": [
        "**Hurricane Harvey:**\n",
        "\n",
        "http://www.ercot.com/help/harvey\n",
        "\n",
        "https://www.eia.gov/todayinenergy/detail.php?id=32892"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgh-J2Lb1ZhP"
      },
      "source": [
        "import os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "from scipy import stats\n",
        "from scipy.optimize import curve_fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os9tnGyjyJbU"
      },
      "source": [
        "#Irma\n",
        "Irma_dt_adult = pd.read_excel('......./irma/Results (Irma_Hourly).xlsx')\n",
        "Irma_dt_adult_3 = pd.read_excel('......./irma/Results (Irma_3hour).xlsx')\n",
        "Irma_dt_adult_d = pd.read_excel('......./irma/Results (Irma_Daily).xlsx')\n",
        "Irma_dt_adult_d_130 = pd.read_excel('......./Initial tweets/LIWC2015 Results (irma250_Daily).xlsx')\n",
        "\n",
        "# Harvey\n",
        "Harvey_dt_adult = pd.read_excel('......./Harvey/Results (Harvey_Hourly).xlsx')\n",
        "Harvey_dt_adult_3 = pd.read_excel('......./Harvey/Results (Harvey_3hour).xlsx')\n",
        "Harvey_dt_adult_d = pd.read_excel('......./Harvey/Results (Harvey_Daily).xlsx')\n",
        "Harvey_dt_adult_d_130 = pd.read_excel('......./LIWC2015 Results (Harvey250_dayly).xlsx')\n",
        "\n",
        "\n",
        "Irma_severity=[1,2,3,4,5,5,5,4,4,4,3,2,1]             #start 09-01\n",
        "Harvey_sevirty=[4,4,4,4,4,4,3,2,1,1,0,0,0,0,0,0,0,0]  #start 08-25\n",
        "List=[Irma_dt_adult,Irma_dt_adult_3,Harvey_dt_adult,Harvey_dt_adult_3]\n",
        "\n",
        "\n",
        "def filling_missing_value(X):\n",
        "  for i in range(len(X)):\n",
        "    Y=''\n",
        "    Z='' \n",
        "    for j  in range(len(X)):\n",
        "        if X[i-j]!='': Y= X[i-j]\n",
        "        if Y !='': break    \n",
        "    for k in range(len(X)):\n",
        "        if X[i+k]!='': Z= X[i+k]\n",
        "        if Z !='': break \n",
        "    if  j+k !=0: X[i]= (k/(j+k))*Y + (j/(j+k))* Z; \n",
        "  return X\n",
        "\n",
        "\n",
        "for i in range(len(List)):\n",
        "    List[i]['severity']=''\n",
        "    List[i]['time_lable']=''\n",
        "    List[i]['Event']=''\n",
        "for i in range(len(List)):\n",
        "    for j in range(List[i].shape[0]):\n",
        "       X=str(int(List[i]['time'][j])-2017000000)  \n",
        "       List[i].at[j,'time_lable']=X[:-4]+'-'+X[-4:-2]+'-'+X[-2:]\n",
        "    if i<= 1:\n",
        "       List[i].at[0,'severity']=Irma_severity[0]/5\n",
        "       List[i].at[List[i].shape[0]-1,'severity']=Irma_severity[len(Irma_severity)-1]/5\n",
        "       K=int(List[i].shape[0]/len(Irma_severity))\n",
        "       n=K\n",
        "       for j in range(len(Irma_severity)-2):\n",
        "           List[i].at[n,'severity']=Irma_severity[j+1]/5\n",
        "           n=n+K\n",
        "       List[i]['severity']=filling_missing_value(List[i]['severity'])\n",
        "       for j in range(List[i].shape[0]):\n",
        "           List[i].at[j,'Event']='Irma 2017, Florida'\n",
        "    if i>1:\n",
        "        List[i].at[0,'severity']=Harvey_sevirty[0]/5\n",
        "        List[i].at[List[i].shape[0]-1,'severity']=Harvey_sevirty[len(Harvey_sevirty)-1]/5\n",
        "        K=int(List[i].shape[0]/len(Harvey_sevirty))\n",
        "        n=K\n",
        "        for j in range(len(Harvey_sevirty)-2):\n",
        "           List[i].at[n,'severity']=Harvey_sevirty[j+1]/5\n",
        "           n=n+K\n",
        "        List[i]['severity']=filling_missing_value(List[i]['severity']) \n",
        "        for j in range(List[i].shape[0]):\n",
        "           List[i].at[j,'Event']='Harvey 2017, Texas'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8WkE41UhiiZ"
      },
      "source": [
        "###for  News and emergency services\n",
        "#List=[Irma_dt_adult,Irma_dt_adult_3,Harvey_dt_adult,Harvey_dt_adult_3]\n",
        "List=[List[0],List[1],List[2],List[3]]\n",
        "\n",
        "for i in range(len(List)):\n",
        "    List[i]['fake']=''\n",
        "    List[i]['CNN_pos']=''\n",
        "    List[i]['EMS']=''\n",
        "    List[i]['info_seek_GT']=''\n",
        "\n",
        "def  fillin_mising_hour(Irma_severity,List,feature):\n",
        "    #List[feature]=''\n",
        "    List.at[0,feature]=Irma_severity[0]\n",
        "    List.at[List.shape[0]-1,feature]=Irma_severity[len(Irma_severity)-1]\n",
        "    K=int(List.shape[0]/len(Irma_severity))\n",
        "    n=K\n",
        "    for j in range(len(Irma_severity)-2):\n",
        "           List.at[n,feature]=Irma_severity[j+1]\n",
        "           n=n+K\n",
        "    List[feature]=filling_missing_value(List[feature])\n",
        "    return  List\n",
        "\n",
        "\n",
        "for i in range(len(List)):\n",
        "    if i<= 1:\n",
        "                  List[i]=fillin_mising_hour(fake_irma,List[i],'fake')\n",
        "                  List[i]=fillin_mising_hour(CNN_irma_pos,List[i],'CNN_pos')\n",
        "                  List[i]=fillin_mising_hour(EMS_irma_mean,List[i],'EMS')\n",
        "                  List[i]=fillin_mising_hour(info_irma,List[i],'info_seek_GT')\n",
        "    if i>1:\n",
        "                  List[i]=fillin_mising_hour(fake_harvey,List[i],'fake')\n",
        "                  List[i]=fillin_mising_hour(CNN_harvey_pos,List[i],'CNN_pos')\n",
        "                  List[i]=fillin_mising_hour(np.array(EMS_harvey_mean),List[i],'EMS')\n",
        "                  List[i]=fillin_mising_hour(info_harvey,List[i],'info_seek_GT')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}