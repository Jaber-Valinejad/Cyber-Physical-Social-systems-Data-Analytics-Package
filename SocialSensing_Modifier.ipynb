{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJQQveb5G-NZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300ab03c-d27d-4b7b-fd66-8694a9148ae8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTCJPEihehaV"
      },
      "source": [
        "import tweepy\n",
        "import datetime \n",
        "consumer_key = \"--------\"\n",
        "consumer_secret = \"--------\"\n",
        "access_token = \"--------\"\n",
        "access_token_secret = \"--------\"\n",
        "\n",
        "\n",
        "# Creating the authentication object\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# Setting your access token and secret\n",
        "auth.set_access_token(access_token, access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFc0PathHeRt"
      },
      "source": [
        "#Tweeter historical database\n",
        "\n",
        "https://catalog.docnow.io/\n",
        "\n",
        "https://tweetsets.library.gwu.edu/\n",
        "   \n",
        "https://snap.stanford.edu/data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2wr_H4c93DD"
      },
      "source": [
        "# Hydrate\n",
        "\n",
        "https://github.com/lopezbec/COVID19_Tweets_Dataset/blob/master/Old_Tweets_ID_by_keyword/Automatically_Hydrate_TweetsIDs_COVID19.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kx4URQEHYuw"
      },
      "source": [
        "# Refrences:\n",
        "https://programminghistorian.org/en/lessons/beginners-guide-to-twitter-data\n",
        "\n",
        "https://towardsdatascience.com/twitter-json-data-processing-3f353a5deac4\n",
        "\n",
        "Example: https://github.com/hectoramirez/Language-localization_FIFA\n",
        "\n",
        "Tweeter REST API: https://towardsdatascience.com/downloading-data-from-twitter-using-the-rest-api-24becf413875\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQhqNwgTva4O"
      },
      "source": [
        "import os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "YVBLHmKa1dob",
        "outputId": "1285fdb8-decc-4ae8-c143-343d93fc0ce6"
      },
      "source": [
        "#Harvey\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Harvey/tweet-ids-001.csv')\n",
        "   ######Samling smapling\n",
        "        ####   217 tweets Ids hastag serch on electricity,power system,power systems,\n",
        "              # electric,DER,power plant,distributed generation,micro grid, power utility, \n",
        "              #electric utility,renewable energy, blackout,power grid,power network\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Harvey_sampling/217_harvey_electrci_1.csv')\n",
        "              #### 11500 tweets Ids include any electric related word\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Harvey_sampling/11500harvey_electrci_any.csv')\n",
        "             #### 20000 tweets Ids sampling \n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Harvey_sampling/20000sample_harvey_1.csv')\n",
        "\n",
        "\n",
        "#Irma\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Irma/tweet-ids-001.csv')\n",
        "      ####   271 tweets Ids hastag serch on electricity,power system,power systems,\n",
        "            # electric,DER,power plant,distributed generation,micro grid, power utility, \n",
        "            #electric utility,renewable energy, blackout,power grid,power network\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Irma_sampling/271_Irma_electrci_1.csv')\n",
        "            #### 54100 tweets Ids include any electric related word\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Irma_sampling/55400Irma_electrci_any.csv')\n",
        "            #### 30000 tweets Ids sampling \n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/1 Getting Tweets +raw outage/Tweeters modifiers/Irma_sampling/30000sample_irma.csv')\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "######                new data: 125,000 tweets for irma, harvey, and florance \n",
        "#florance\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/7- Industrial informatics/Initial tweets/Florence.csv')\n",
        "#harvey\n",
        "dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/7- Industrial informatics/Initial tweets/Harvey.csv')\n",
        "#irma\n",
        "#dt_adult = pd.read_csv('/content/drive/Shareddrives/MY Files/Validation-power system/7- Industrial informatics/Initial tweets/irma250.csv')\n",
        "\n",
        "#pd.read_csv\n",
        "print('Size of data before sampling:',dt_adult.shape)\n",
        "Data=pd.DataFrame(dt_adult )\n",
        "Data.head()\n",
        "#Data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of data before sampling: (136088, 34)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  coordinates                      created_at                        hashtags  \\\n",
              "0         NaN  Mon Sep 11 08:28:42 +0000 2017      hurricane storm miami irma   \n",
              "1         NaN  Mon Aug 28 04:30:31 +0000 2017                             NaN   \n",
              "2         NaN  Mon Sep 11 08:54:06 +0000 2017  dog hurricane storm miami irma   \n",
              "3         NaN  Tue Aug 29 07:19:53 +0000 2017                             NaN   \n",
              "4         NaN  Sun Sep 03 18:40:14 +0000 2017                             NaN   \n",
              "\n",
              "  media                                               urls  favorite_count  \\\n",
              "0   NaN  https://twitter.com/tumblrCol/status/906565798...               0   \n",
              "1   NaN                                                NaN               0   \n",
              "2   NaN  https://twitter.com/tumblrCol/status/906565798...               0   \n",
              "3   NaN  https://twitter.com/AnnCoulter/status/90237301...               0   \n",
              "4   NaN  https://twitter.com/latimes/status/90386258319...               0   \n",
              "\n",
              "                   id in_reply_to_screen_name  in_reply_to_status_id  \\\n",
              "0  907158949425811456                     NaN                    NaN   \n",
              "1  902025579968569345                     NaN                    NaN   \n",
              "2  907165340865626112                     NaN                    NaN   \n",
              "3  902430589567021056                     NaN                    NaN   \n",
              "4  904413742800220161                     NaN                    NaN   \n",
              "\n",
              "   in_reply_to_user_id  ... user_followers_count user_friends_count  \\\n",
              "0                  NaN  ...                  467               1364   \n",
              "1                  NaN  ...                   55                908   \n",
              "2                  NaN  ...                 1213               2087   \n",
              "3                  NaN  ...                  259                262   \n",
              "4                  NaN  ...                 1459               1489   \n",
              "\n",
              "  user_listed_count             user_location      user_name  \\\n",
              "0                 3          askam-in-furness      James New   \n",
              "1                 0                       NaN  Tracey Simons   \n",
              "2               352  Capital Region, New York  Jason Rotella   \n",
              "3                27                       NaN          Jessy   \n",
              "4                10                   ela/elu  rational kwen   \n",
              "\n",
              "  user_screen_name.1 user_statuses_count user_time_zone  \\\n",
              "0          big_chip9                9889            NaN   \n",
              "1      tracey_simons                6255            NaN   \n",
              "2           Jay_AHR_               13672            NaN   \n",
              "3       FreesideKing               51507            NaN   \n",
              "4         liabiliwty              105074            NaN   \n",
              "\n",
              "                              user_urls user_verified  \n",
              "0                                   NaN         False  \n",
              "1                                   NaN         False  \n",
              "2  https://linkedIn.com/in/jasonrotella         False  \n",
              "3                                   NaN         False  \n",
              "4        https://beachatoms.tumblr.com/         False  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae51cfbd-66bf-44cc-a0b5-26532f7574b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>media</th>\n",
              "      <th>urls</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>...</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_listed_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_screen_name.1</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_time_zone</th>\n",
              "      <th>user_urls</th>\n",
              "      <th>user_verified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Sep 11 08:28:42 +0000 2017</td>\n",
              "      <td>hurricane storm miami irma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/tumblrCol/status/906565798...</td>\n",
              "      <td>0</td>\n",
              "      <td>907158949425811456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>467</td>\n",
              "      <td>1364</td>\n",
              "      <td>3</td>\n",
              "      <td>askam-in-furness</td>\n",
              "      <td>James New</td>\n",
              "      <td>big_chip9</td>\n",
              "      <td>9889</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Aug 28 04:30:31 +0000 2017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>902025579968569345</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>55</td>\n",
              "      <td>908</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tracey Simons</td>\n",
              "      <td>tracey_simons</td>\n",
              "      <td>6255</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Sep 11 08:54:06 +0000 2017</td>\n",
              "      <td>dog hurricane storm miami irma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/tumblrCol/status/906565798...</td>\n",
              "      <td>0</td>\n",
              "      <td>907165340865626112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1213</td>\n",
              "      <td>2087</td>\n",
              "      <td>352</td>\n",
              "      <td>Capital Region, New York</td>\n",
              "      <td>Jason Rotella</td>\n",
              "      <td>Jay_AHR_</td>\n",
              "      <td>13672</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://linkedIn.com/in/jasonrotella</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Tue Aug 29 07:19:53 +0000 2017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/AnnCoulter/status/90237301...</td>\n",
              "      <td>0</td>\n",
              "      <td>902430589567021056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>259</td>\n",
              "      <td>262</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jessy</td>\n",
              "      <td>FreesideKing</td>\n",
              "      <td>51507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Sep 03 18:40:14 +0000 2017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/latimes/status/90386258319...</td>\n",
              "      <td>0</td>\n",
              "      <td>904413742800220161</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1459</td>\n",
              "      <td>1489</td>\n",
              "      <td>10</td>\n",
              "      <td>ela/elu</td>\n",
              "      <td>rational kwen</td>\n",
              "      <td>liabiliwty</td>\n",
              "      <td>105074</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://beachatoms.tumblr.com/</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae51cfbd-66bf-44cc-a0b5-26532f7574b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae51cfbd-66bf-44cc-a0b5-26532f7574b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae51cfbd-66bf-44cc-a0b5-26532f7574b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "OtD9pt8_xWYq",
        "outputId": "d489e16b-5b19-4fb7-f490-5fa454e42e37"
      },
      "source": [
        "data_tweet = pd.DataFrame()\n",
        "data_tweet['id']= Data['id']\n",
        "data_tweet['Time']= Data['created_at']\n",
        "data_tweet['text']= Data['text']\n",
        "data_tweet['user_followers_count']= Data['user_followers_count']\n",
        "data_tweet['user_followee_count']= Data['user_friends_count']\n",
        "data_tweet['user_location']= Data['user_location']\n",
        "#data_tweet['coordinates']= Data['coordinates']\n",
        "#data_tweet['place']= Data['place']\n",
        "data_tweet['lang']= Data['lang']\n",
        "data_tweet['lang']= Data['lang']\n",
        "data_tweet.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   id                            Time  \\\n",
              "0  907158949425811456  Mon Sep 11 08:28:42 +0000 2017   \n",
              "1  902025579968569345  Mon Aug 28 04:30:31 +0000 2017   \n",
              "2  907165340865626112  Mon Sep 11 08:54:06 +0000 2017   \n",
              "3  902430589567021056  Tue Aug 29 07:19:53 +0000 2017   \n",
              "4  904413742800220161  Sun Sep 03 18:40:14 +0000 2017   \n",
              "\n",
              "                                                text  user_followers_count  \\\n",
              "0  RT @NickKuk: This guys saving dogs!!! #hurrica...                   467   \n",
              "1  RT @houstonpolice: Rain is coming down and we ...                    55   \n",
              "2  RT @RupertTheDog_: In #dog news! Human hero! “...                  1213   \n",
              "3  RT @Epyonzilla: Ah ouais, de bon matin, comme ...                   259   \n",
              "4  RT @arjan____: look at that lil face. it's get...                  1459   \n",
              "\n",
              "   user_followee_count             user_location lang  \n",
              "0                 1364          askam-in-furness   en  \n",
              "1                  908                       NaN   en  \n",
              "2                 2087  Capital Region, New York   en  \n",
              "3                  262                       NaN   fr  \n",
              "4                 1489                   ela/elu   en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65c4d846-d267-4b76-bdf0-cc986cec85ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_followee_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>907158949425811456</td>\n",
              "      <td>Mon Sep 11 08:28:42 +0000 2017</td>\n",
              "      <td>RT @NickKuk: This guys saving dogs!!! #hurrica...</td>\n",
              "      <td>467</td>\n",
              "      <td>1364</td>\n",
              "      <td>askam-in-furness</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>902025579968569345</td>\n",
              "      <td>Mon Aug 28 04:30:31 +0000 2017</td>\n",
              "      <td>RT @houstonpolice: Rain is coming down and we ...</td>\n",
              "      <td>55</td>\n",
              "      <td>908</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>907165340865626112</td>\n",
              "      <td>Mon Sep 11 08:54:06 +0000 2017</td>\n",
              "      <td>RT @RupertTheDog_: In #dog news! Human hero! “...</td>\n",
              "      <td>1213</td>\n",
              "      <td>2087</td>\n",
              "      <td>Capital Region, New York</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>902430589567021056</td>\n",
              "      <td>Tue Aug 29 07:19:53 +0000 2017</td>\n",
              "      <td>RT @Epyonzilla: Ah ouais, de bon matin, comme ...</td>\n",
              "      <td>259</td>\n",
              "      <td>262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>904413742800220161</td>\n",
              "      <td>Sun Sep 03 18:40:14 +0000 2017</td>\n",
              "      <td>RT @arjan____: look at that lil face. it's get...</td>\n",
              "      <td>1459</td>\n",
              "      <td>1489</td>\n",
              "      <td>ela/elu</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65c4d846-d267-4b76-bdf0-cc986cec85ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65c4d846-d267-4b76-bdf0-cc986cec85ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65c4d846-d267-4b76-bdf0-cc986cec85ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-0VKoiXNd_"
      },
      "source": [
        "# Date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "JrO-uAvHKE4e",
        "outputId": "8874ce1d-34b4-4e5e-a2b2-8ff312408208"
      },
      "source": [
        "import time\n",
        "OK=data_tweet['Time']\n",
        "df = pd.DataFrame()\n",
        "df['Time']=''\n",
        "df['Time hour']=''\n",
        "data_tweet['Year']=''\n",
        "data_tweet['Month']=''\n",
        "data_tweet['Day']=''\n",
        "data_tweet['Hour']=''\n",
        "\n",
        "for i in range(OK.shape[0]):\n",
        "   X=OK[i]\n",
        "   #Y= time.strftime('%Y%m%d%H', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   Y= time.strftime('%Y%m%d', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   df.at[i,'Time']=pd.to_numeric(Y)\n",
        "\n",
        "   Y1= time.strftime('%Y', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   Y2= time.strftime('%m', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   Y3= time.strftime('%d', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   Y4= time.strftime('%H', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   data_tweet.at[i,'Year']=pd.to_numeric(Y1)\n",
        "   data_tweet.at[i,'Month']=pd.to_numeric(Y2)\n",
        "   data_tweet.at[i,'Day']=pd.to_numeric(Y3)\n",
        "   data_tweet.at[i,'Hour']=pd.to_numeric(Y4)\n",
        "   YY= time.strftime('%Y%m%d%H', time.strptime(X,'%a %b %d %H:%M:%S +0000 %Y'))\n",
        "   data_tweet.at[i,'Time hour']=pd.to_numeric(YY)\n",
        "\n",
        "\n",
        "#data_tweet['Time']\n",
        "data_tweet.drop(['Time'], axis=1, inplace=True)\n",
        "data_tweet['time']=df['Time']\n",
        "data_tweet=data_tweet.sort_values(by=['time'])\n",
        "data_tweet2=data_tweet.copy()\n",
        "data_tweet3=data_tweet.copy()\n",
        "data_tweet4=data_tweet.copy()\n",
        "data_tweet.head(10)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                                               text  \\\n",
              "130027  901195096678252544  RT @NWSHouston: 4pm update from NHC shows Hurr...   \n",
              "4276    901147431680606208  Satellite images show Hurricane Harvey beginni...   \n",
              "30062   901184462498803712                Ewwwwwwwww. https://t.co/tdHEaxfhxY   \n",
              "16035   901198968738242560  RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...   \n",
              "4273    901195242740879361  RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...   \n",
              "43223   901179829848080386  RT @ABC: #Harvey is forecast to become a Cat 3...   \n",
              "28230   901198417237610500  RT @annemariehams: Prayers being offered to th...   \n",
              "123935  901195703694839809  RT @Deanofcomedy: Interesting how Republicans ...   \n",
              "4267    901147434658746368  RT @RepBarbaraLee: My thoughts &amp; prayers a...   \n",
              "38042   901178999564455936  RT @MattMurph24: Never forget. https://t.co/rh...   \n",
              "\n",
              "        user_followers_count  user_followee_count      user_location lang  \\\n",
              "130027                   348                  141            Canada    en   \n",
              "4276                      35                   87                NaN   en   \n",
              "30062                    301                  361         Texas, USA  und   \n",
              "16035                    290                  513   Augusta, Georgia   en   \n",
              "4273                     276                  880                NaN   en   \n",
              "43223                    176                  476      United States   en   \n",
              "28230                   1164                 2466                 IL   en   \n",
              "123935                  6137                 2314                NaN   en   \n",
              "4267                    6362                  587  Pennsylvania, USA   en   \n",
              "38042                     20                  780                NaN   en   \n",
              "\n",
              "        Year Month Day Hour     Time hour      time  \n",
              "130027  2017     8  25   21  2.017083e+09  20170825  \n",
              "4276    2017     8  25   18  2.017083e+09  20170825  \n",
              "30062   2017     8  25   20  2.017083e+09  20170825  \n",
              "16035   2017     8  25   21  2.017083e+09  20170825  \n",
              "4273    2017     8  25   21  2.017083e+09  20170825  \n",
              "43223   2017     8  25   20  2.017083e+09  20170825  \n",
              "28230   2017     8  25   21  2.017083e+09  20170825  \n",
              "123935  2017     8  25   21  2.017083e+09  20170825  \n",
              "4267    2017     8  25   18  2.017083e+09  20170825  \n",
              "38042   2017     8  25   20  2.017083e+09  20170825  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a67970ef-2da3-4990-82f5-33c93e507ebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_followee_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>lang</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Time hour</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130027</th>\n",
              "      <td>901195096678252544</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "      <td>348</td>\n",
              "      <td>141</td>\n",
              "      <td>Canada</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>901147431680606208</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "      <td>35</td>\n",
              "      <td>87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30062</th>\n",
              "      <td>901184462498803712</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxY</td>\n",
              "      <td>301</td>\n",
              "      <td>361</td>\n",
              "      <td>Texas, USA</td>\n",
              "      <td>und</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16035</th>\n",
              "      <td>901198968738242560</td>\n",
              "      <td>RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...</td>\n",
              "      <td>290</td>\n",
              "      <td>513</td>\n",
              "      <td>Augusta, Georgia</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4273</th>\n",
              "      <td>901195242740879361</td>\n",
              "      <td>RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...</td>\n",
              "      <td>276</td>\n",
              "      <td>880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43223</th>\n",
              "      <td>901179829848080386</td>\n",
              "      <td>RT @ABC: #Harvey is forecast to become a Cat 3...</td>\n",
              "      <td>176</td>\n",
              "      <td>476</td>\n",
              "      <td>United States</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28230</th>\n",
              "      <td>901198417237610500</td>\n",
              "      <td>RT @annemariehams: Prayers being offered to th...</td>\n",
              "      <td>1164</td>\n",
              "      <td>2466</td>\n",
              "      <td>IL</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123935</th>\n",
              "      <td>901195703694839809</td>\n",
              "      <td>RT @Deanofcomedy: Interesting how Republicans ...</td>\n",
              "      <td>6137</td>\n",
              "      <td>2314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4267</th>\n",
              "      <td>901147434658746368</td>\n",
              "      <td>RT @RepBarbaraLee: My thoughts &amp;amp; prayers a...</td>\n",
              "      <td>6362</td>\n",
              "      <td>587</td>\n",
              "      <td>Pennsylvania, USA</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38042</th>\n",
              "      <td>901178999564455936</td>\n",
              "      <td>RT @MattMurph24: Never forget. https://t.co/rh...</td>\n",
              "      <td>20</td>\n",
              "      <td>780</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a67970ef-2da3-4990-82f5-33c93e507ebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a67970ef-2da3-4990-82f5-33c93e507ebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a67970ef-2da3-4990-82f5-33c93e507ebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xK6NnFAALp7"
      },
      "source": [
        "#data_tweet['time'].max()\n",
        "#data_tweet['Time hour'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "SjfC8ikBb8a6",
        "outputId": "c0c22c28-7732-423f-9890-30efd7cb073b"
      },
      "source": [
        "data_tweet2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                                               text  \\\n",
              "130027  901195096678252544  RT @NWSHouston: 4pm update from NHC shows Hurr...   \n",
              "4276    901147431680606208  Satellite images show Hurricane Harvey beginni...   \n",
              "30062   901184462498803712                Ewwwwwwwww. https://t.co/tdHEaxfhxY   \n",
              "16035   901198968738242560  RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...   \n",
              "4273    901195242740879361  RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...   \n",
              "...                    ...                                                ...   \n",
              "1567    907168783747383296  Plus @HaleyKPRC on #Back2School anxiety some s...   \n",
              "1569    907168909836636160  RT @NickKuk: This guys saving dogs!!! #hurrica...   \n",
              "1570    907168960529002496  RT @NickKuk: This guys saving dogs!!! #hurrica...   \n",
              "73259   907174238733381633  RT @NickKuk: This guys saving dogs!!! #hurrica...   \n",
              "0       907158949425811456  RT @NickKuk: This guys saving dogs!!! #hurrica...   \n",
              "\n",
              "        user_followers_count  user_followee_count     user_location lang  \\\n",
              "130027                   348                  141           Canada    en   \n",
              "4276                      35                   87               NaN   en   \n",
              "30062                    301                  361        Texas, USA  und   \n",
              "16035                    290                  513  Augusta, Georgia   en   \n",
              "4273                     276                  880               NaN   en   \n",
              "...                      ...                  ...               ...  ...   \n",
              "1567                   17484                 1214       Phoenix, AZ   en   \n",
              "1569                     192                  182               NaN   en   \n",
              "1570                     815                  576   Bridgend, Wales   en   \n",
              "73259                    413                  163          Coventry   en   \n",
              "0                        467                 1364  askam-in-furness   en   \n",
              "\n",
              "        Year Month Day Hour     Time hour      time  \n",
              "130027  2017     8  25   21  2.017083e+09  20170825  \n",
              "4276    2017     8  25   18  2.017083e+09  20170825  \n",
              "30062   2017     8  25   20  2.017083e+09  20170825  \n",
              "16035   2017     8  25   21  2.017083e+09  20170825  \n",
              "4273    2017     8  25   21  2.017083e+09  20170825  \n",
              "...      ...   ...  ..  ...           ...       ...  \n",
              "1567    2017     9  11    9  2.017091e+09  20170911  \n",
              "1569    2017     9  11    9  2.017091e+09  20170911  \n",
              "1570    2017     9  11    9  2.017091e+09  20170911  \n",
              "73259   2017     9  11    9  2.017091e+09  20170911  \n",
              "0       2017     9  11    8  2.017091e+09  20170911  \n",
              "\n",
              "[136088 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-116a5a93-69dc-42a8-9237-74a01ba77df0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_followee_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>lang</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Time hour</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130027</th>\n",
              "      <td>901195096678252544</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "      <td>348</td>\n",
              "      <td>141</td>\n",
              "      <td>Canada</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>901147431680606208</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "      <td>35</td>\n",
              "      <td>87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30062</th>\n",
              "      <td>901184462498803712</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxY</td>\n",
              "      <td>301</td>\n",
              "      <td>361</td>\n",
              "      <td>Texas, USA</td>\n",
              "      <td>und</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16035</th>\n",
              "      <td>901198968738242560</td>\n",
              "      <td>RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...</td>\n",
              "      <td>290</td>\n",
              "      <td>513</td>\n",
              "      <td>Augusta, Georgia</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4273</th>\n",
              "      <td>901195242740879361</td>\n",
              "      <td>RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...</td>\n",
              "      <td>276</td>\n",
              "      <td>880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1567</th>\n",
              "      <td>907168783747383296</td>\n",
              "      <td>Plus @HaleyKPRC on #Back2School anxiety some s...</td>\n",
              "      <td>17484</td>\n",
              "      <td>1214</td>\n",
              "      <td>Phoenix, AZ</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2.017091e+09</td>\n",
              "      <td>20170911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1569</th>\n",
              "      <td>907168909836636160</td>\n",
              "      <td>RT @NickKuk: This guys saving dogs!!! #hurrica...</td>\n",
              "      <td>192</td>\n",
              "      <td>182</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2.017091e+09</td>\n",
              "      <td>20170911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1570</th>\n",
              "      <td>907168960529002496</td>\n",
              "      <td>RT @NickKuk: This guys saving dogs!!! #hurrica...</td>\n",
              "      <td>815</td>\n",
              "      <td>576</td>\n",
              "      <td>Bridgend, Wales</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2.017091e+09</td>\n",
              "      <td>20170911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73259</th>\n",
              "      <td>907174238733381633</td>\n",
              "      <td>RT @NickKuk: This guys saving dogs!!! #hurrica...</td>\n",
              "      <td>413</td>\n",
              "      <td>163</td>\n",
              "      <td>Coventry</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2.017091e+09</td>\n",
              "      <td>20170911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>907158949425811456</td>\n",
              "      <td>RT @NickKuk: This guys saving dogs!!! #hurrica...</td>\n",
              "      <td>467</td>\n",
              "      <td>1364</td>\n",
              "      <td>askam-in-furness</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>2.017091e+09</td>\n",
              "      <td>20170911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136088 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-116a5a93-69dc-42a8-9237-74a01ba77df0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-116a5a93-69dc-42a8-9237-74a01ba77df0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-116a5a93-69dc-42a8-9237-74a01ba77df0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0__DxbmzsBod"
      },
      "source": [
        "# Mixing days/hour: text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1GJUdPjkrWY"
      },
      "source": [
        "#daily\n",
        "#data_tweet.drop(['id','user_followers_count','user_followee_count','lang','user_location',\"Month\",\"Day\",'Hour','Year','Time hour'], axis=1, inplace=True)\n",
        "#data_tweet21 = data_tweet.groupby([\"Month\",\"Day\",'Hour']).sum()\n",
        "data_tweet21 = data_tweet.groupby(['time']).sum()\n",
        "data_tweet21.head()\n",
        "#data_tweet2['text'][20170825]\n",
        "\n",
        "#hourly\n",
        "#data_tweet=data_tweet3\n",
        "#data_tweet2=data_tweet4\n",
        "#data_tweet.drop(['id','user_followers_count','user_followee_count','lang','user_location',\"Month\",\"Day\",'Hour','Year','time'], axis=1, inplace=True)\n",
        "#data_tweet1 = data_tweet.groupby(['Time hour']).sum()\n",
        "#data_tweet1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptaOKAU8hf2D"
      },
      "source": [
        "\n",
        "\n",
        "Mixing days/hour: frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "4AO_uhoshfVm",
        "outputId": "bd0aac03-47cb-4b32-c51f-9b5731d39261"
      },
      "source": [
        "#hourly\n",
        "data_tweet2.drop(['id','user_followers_count','text','user_followee_count','lang','user_location',\"Month\",\"Day\",'Hour','Year','time'], axis=1, inplace=True)\n",
        "data_tweet_frequency = data_tweet2.pivot_table(index=['Time hour'], aggfunc='size')\n",
        "data_tweet=data_tweet2.groupby(['Time hour']).sum()\n",
        "data_tweet['frequency']=data_tweet_frequency \n",
        "data_tweet.head()\n",
        "ALL_Data=data_tweet.merge(data_tweet1, on='Time hour')\n",
        "ALL_Data.head()\n",
        "\n",
        "#Daily\n",
        "#data_tweet2.drop(['id','user_followers_count','text','user_followee_count','lang','user_location',\"Month\",\"Day\",'Hour','Year','Time hour'], axis=1, inplace=True)\n",
        "#data_tweet_frequency = data_tweet2.pivot_table(index=['time'], aggfunc='size')\n",
        "#data_tweet=data_tweet2.groupby(['time']).sum()\n",
        "#data_tweet['frequency']=data_tweet_frequency \n",
        "#data_tweet.head()\n",
        "#ALL_Data=data_tweet.merge(data_tweet21, on='time')\n",
        "#ALL_Data.head()\n",
        "#data_tweet.to_excel('/content/drive/Shareddrives/MY Files/Tweeter Data/output.xlsx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time hour</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>76</td>\n",
              "      <td>RT @jilevin: Hurricane Harvey Will Cause Disas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>742</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>716</td>\n",
              "      <td>RT @rickreichmuth: Latest radar image of Harve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1746</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxYRT @ABC: #H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2537</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              frequency                                               text\n",
              "Time hour                                                                 \n",
              "2.017083e+09         76  RT @jilevin: Hurricane Harvey Will Cause Disas...\n",
              "2.017083e+09        742  Satellite images show Hurricane Harvey beginni...\n",
              "2.017083e+09        716  RT @rickreichmuth: Latest radar image of Harve...\n",
              "2.017083e+09       1746  Ewwwwwwwww. https://t.co/tdHEaxfhxYRT @ABC: #H...\n",
              "2.017083e+09       2537  RT @NWSHouston: 4pm update from NHC shows Hurr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnSN1lxQ41mn"
      },
      "source": [
        "# Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "CaXI5_tyuLbw",
        "outputId": "a117015d-6829-40ff-e4c2-fa312ad9f3f8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "#from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import regexp\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "#import docx\n",
        "#import docx2txt\n",
        " \n",
        "ALL_Data['texte_cleaned']=''\n",
        "#result = docx2txt.process(\"C:/Users/JabV/Desktop/DAta Cleaned/RD  monthly/Real/SF/7 July.docx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    \"\"\"Remove special patterns - email, url, date etc.\"\"\"\n",
        "    email_regex = re.compile(r\"[\\w.-]+@[\\w.-]+\")\n",
        "    url_regex = re.compile(r\"(http|www)[^\\s]+\")\n",
        "    date_regex = re.compile(r\"[\\d]{2,4}[ -/:]*[\\d]{2,4}([ -/:]*[\\d]{2,4})?\") # a way to match date\n",
        "    ## remove\n",
        "    text = url_regex.sub(\"\", text)\n",
        "    text = email_regex.sub(\"\", text)\n",
        "    text = date_regex.sub(\"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
        "    return no_punct\n",
        "\n",
        "\n",
        "\n",
        "#1 No tokenize\n",
        "#tokenized_text=result2.lower()\n",
        "\n",
        "#2 Tokenize\n",
        "word_tokenizer = regexp.WhitespaceTokenizer()\n",
        "#tokenized_text = [word.lower() for word in word_tokenizer.tokenize(result2)]\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words=[w for w in text if w not in stopwords.words('english')]\n",
        "    return words\n",
        "\n",
        "  \n",
        "stemmer=PorterStemmer()\n",
        "def word_stemmer(text):\n",
        "    stem_text=\" \".join([stemmer.stem(i) for i in text])\n",
        "    return stem_text\n",
        "\n",
        "\n",
        "\n",
        "for i in range(ALL_Data.shape[0]):\n",
        "  j=ALL_Data.index[i]\n",
        "  result=ALL_Data['text'][j]\n",
        "  result1=remove_html(result)\n",
        "  result2=remove_punctuation(result1)\n",
        "  tokenized_text = [word.lower() for word in word_tokenizer.tokenize(result2)]\n",
        "  result3=remove_stopwords(tokenized_text)\n",
        "  result4=word_stemmer(result3)\n",
        "  ALL_Data.at[j,'texte_cleaned']=result4\n",
        "ALL_Data.head()\n",
        "#mydoc = docx.Document()\n",
        "#mydoc.add_paragraph(result4)\n",
        "#mydoc.save(\"C:/Users/JabV/Desktop/DAta Cleaned/RD  monthly/Real/SF/7 July.docx\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>text</th>\n",
              "      <th>texte_cleaned</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time hour</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>76</td>\n",
              "      <td>RT @jilevin: Hurricane Harvey Will Cause Disas...</td>\n",
              "      <td>rt jilevin hurrican harvey caus disastr flood ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>742</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "      <td>satellit imag show hurrican harvey begin reach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>716</td>\n",
              "      <td>RT @rickreichmuth: Latest radar image of Harve...</td>\n",
              "      <td>rt rickreichmuth latest radar imag harvey cate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1746</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxYRT @ABC: #H...</td>\n",
              "      <td>e abc harvey forecast becom cat 3 hurrican app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2537</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "      <td>rt nwshouston 4pm updat nhc show hurrican harv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              frequency  ...                                      texte_cleaned\n",
              "Time hour                ...                                                   \n",
              "2.017083e+09         76  ...  rt jilevin hurrican harvey caus disastr flood ...\n",
              "2.017083e+09        742  ...  satellit imag show hurrican harvey begin reach...\n",
              "2.017083e+09        716  ...  rt rickreichmuth latest radar imag harvey cate...\n",
              "2.017083e+09       1746  ...  e abc harvey forecast becom cat 3 hurrican app...\n",
              "2.017083e+09       2537  ...  rt nwshouston 4pm updat nhc show hurrican harv...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tweet2=data_tweet2[:100]\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "#from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import regexp\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "#import docx\n",
        "#import docx2txt\n",
        " \n",
        "data_tweet2['texte_cleaned']=''\n",
        "#result = docx2txt.process(\"C:/Users/JabV/Desktop/DAta Cleaned/RD  monthly/Real/SF/7 July.docx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    \"\"\"Remove special patterns - email, url, date etc.\"\"\"\n",
        "    email_regex = re.compile(r\"[\\w.-]+@[\\w.-]+\")\n",
        "    url_regex = re.compile(r\"(http|www)[^\\s]+\")\n",
        "    date_regex = re.compile(r\"[\\d]{2,4}[ -/:]*[\\d]{2,4}([ -/:]*[\\d]{2,4})?\") # a way to match date\n",
        "    ## remove\n",
        "    text = url_regex.sub(\"\", text)\n",
        "    text = email_regex.sub(\"\", text)\n",
        "    text = date_regex.sub(\"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
        "    return no_punct\n",
        "\n",
        "\n",
        "\n",
        "#1 No tokenize\n",
        "#tokenized_text=result2.lower()\n",
        "\n",
        "#2 Tokenize\n",
        "word_tokenizer = regexp.WhitespaceTokenizer()\n",
        "#tokenized_text = [word.lower() for word in word_tokenizer.tokenize(result2)]\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words=[w for w in text if w not in stopwords.words('english')]\n",
        "    return words\n",
        "\n",
        "  \n",
        "stemmer=PorterStemmer()\n",
        "def word_stemmer(text):\n",
        "    stem_text=\" \".join([stemmer.stem(i) for i in text])\n",
        "    return stem_text\n",
        "\n",
        "\n",
        "\n",
        "for i in range(data_tweet2.shape[0]):\n",
        "  j=data_tweet2.index[i]\n",
        "  result=data_tweet2['text'][j]\n",
        "  result1=remove_html(result)\n",
        "  result2=remove_punctuation(result1)\n",
        "  tokenized_text = [word.lower() for word in word_tokenizer.tokenize(result2)]\n",
        "  result3=remove_stopwords(tokenized_text)\n",
        "  result4=word_stemmer(result3)\n",
        "  data_tweet2.at[j,'texte_cleaned']=result4\n",
        "data_tweet2.head()\n",
        "#mydoc = docx.Document()\n",
        "#mydoc.add_paragraph(result4)\n",
        "#mydoc.save(\"C:/Users/JabV/Desktop/DAta Cleaned/RD  monthly/Real/SF/7 July.docx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "eYY34woCbRje",
        "outputId": "556463cf-ba04-4cb2-c111-23498f9b118b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                                               text  \\\n",
              "130027  901195096678252544  RT @NWSHouston: 4pm update from NHC shows Hurr...   \n",
              "4276    901147431680606208  Satellite images show Hurricane Harvey beginni...   \n",
              "30062   901184462498803712                Ewwwwwwwww. https://t.co/tdHEaxfhxY   \n",
              "16035   901198968738242560  RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...   \n",
              "4273    901195242740879361  RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...   \n",
              "\n",
              "        user_followers_count  user_followee_count     user_location lang  \\\n",
              "130027                   348                  141           Canada    en   \n",
              "4276                      35                   87               NaN   en   \n",
              "30062                    301                  361        Texas, USA  und   \n",
              "16035                    290                  513  Augusta, Georgia   en   \n",
              "4273                     276                  880               NaN   en   \n",
              "\n",
              "        Year Month Day Hour     Time hour      time  \\\n",
              "130027  2017     8  25   21  2.017083e+09  20170825   \n",
              "4276    2017     8  25   18  2.017083e+09  20170825   \n",
              "30062   2017     8  25   20  2.017083e+09  20170825   \n",
              "16035   2017     8  25   21  2.017083e+09  20170825   \n",
              "4273    2017     8  25   21  2.017083e+09  20170825   \n",
              "\n",
              "                                            texte_cleaned  \n",
              "130027  rt nwshouston 4pm updat nhc show hurrican harv...  \n",
              "4276    satellit imag show hurrican harvey begin reach...  \n",
              "30062                                                   e  \n",
              "16035   rt aspca hurricaneharvey alert store pet recor...  \n",
              "4273    rt texasforevertwt someon put swim vest selena...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22e5af9b-c3a7-41f1-bca5-ceb337e486c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_followee_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>lang</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Time hour</th>\n",
              "      <th>time</th>\n",
              "      <th>texte_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130027</th>\n",
              "      <td>901195096678252544</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "      <td>348</td>\n",
              "      <td>141</td>\n",
              "      <td>Canada</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "      <td>rt nwshouston 4pm updat nhc show hurrican harv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>901147431680606208</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "      <td>35</td>\n",
              "      <td>87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "      <td>satellit imag show hurrican harvey begin reach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30062</th>\n",
              "      <td>901184462498803712</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxY</td>\n",
              "      <td>301</td>\n",
              "      <td>361</td>\n",
              "      <td>Texas, USA</td>\n",
              "      <td>und</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16035</th>\n",
              "      <td>901198968738242560</td>\n",
              "      <td>RT @ASPCA: #HURRICANEHARVEY ALERT: Store pet r...</td>\n",
              "      <td>290</td>\n",
              "      <td>513</td>\n",
              "      <td>Augusta, Georgia</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "      <td>rt aspca hurricaneharvey alert store pet recor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4273</th>\n",
              "      <td>901195242740879361</td>\n",
              "      <td>RT @texasforevertwt: SOMEONE PUT A SWIMMING VE...</td>\n",
              "      <td>276</td>\n",
              "      <td>880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>21</td>\n",
              "      <td>2.017083e+09</td>\n",
              "      <td>20170825</td>\n",
              "      <td>rt texasforevertwt someon put swim vest selena...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22e5af9b-c3a7-41f1-bca5-ceb337e486c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22e5af9b-c3a7-41f1-bca5-ceb337e486c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22e5af9b-c3a7-41f1-bca5-ceb337e486c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_tweet2[['text','texte_cleaned']]\n",
        "X.to_csv('out.csv')"
      ],
      "metadata": {
        "id": "iEJPE0RxcE4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXyoWrZ3y3tu"
      },
      "source": [
        "Make seperate For every other hour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "D2S2cRQ1Nvv_",
        "outputId": "6d54365c-626d-4f5e-8e20-4a2f923c5e76"
      },
      "source": [
        "ALL_Data['Date']=''\n",
        "for i in range(len(ALL_Data)): \n",
        "    ALL_Data['Date'][i]=pd.to_numeric(ALL_Data.index[i])\n",
        "\n",
        "ALL_Data.index = range(len(ALL_Data))\n",
        "ALL_Data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>text</th>\n",
              "      <th>texte_cleaned</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76</td>\n",
              "      <td>RT @jilevin: Hurricane Harvey Will Cause Disas...</td>\n",
              "      <td>rt jilevin hurrican harvey caus disastr flood ...</td>\n",
              "      <td>2.01708e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>742</td>\n",
              "      <td>Satellite images show Hurricane Harvey beginni...</td>\n",
              "      <td>satellit imag show hurrican harvey begin reach...</td>\n",
              "      <td>2.01708e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>716</td>\n",
              "      <td>RT @rickreichmuth: Latest radar image of Harve...</td>\n",
              "      <td>rt rickreichmuth latest radar imag harvey cate...</td>\n",
              "      <td>2.01708e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1746</td>\n",
              "      <td>Ewwwwwwwww. https://t.co/tdHEaxfhxYRT @ABC: #H...</td>\n",
              "      <td>e abc harvey forecast becom cat 3 hurrican app...</td>\n",
              "      <td>2.01708e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2537</td>\n",
              "      <td>RT @NWSHouston: 4pm update from NHC shows Hurr...</td>\n",
              "      <td>rt nwshouston 4pm updat nhc show hurrican harv...</td>\n",
              "      <td>2.01708e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   frequency  ...         Date\n",
              "0         76  ...  2.01708e+09\n",
              "1        742  ...  2.01708e+09\n",
              "2        716  ...  2.01708e+09\n",
              "3       1746  ...  2.01708e+09\n",
              "4       2537  ...  2.01708e+09\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "OP3m0fN16mNN",
        "outputId": "562a5704-5b12-40e5-f48f-fd76841fbb59"
      },
      "source": [
        "import math\n",
        "Every_hour=3\n",
        "a=[]\n",
        "for h in range(ALL_Data.shape[0]): \n",
        "  x=ALL_Data['Date'][h]-math.trunc(ALL_Data['Date'][h]/100)*100 \n",
        "  if x%Every_hour==0:\n",
        "     a.append(ALL_Data['Date'][h]) \n",
        "\n",
        "Data_3hour=pd.DataFrame(index=a)\n",
        "Data_3hour['frequency']=''\n",
        "Data_3hour['texte_cleaned']=''\n",
        "\n",
        "\n",
        "for i in a:\n",
        "     yy=0\n",
        "     for h in range(ALL_Data.shape[0]):   \n",
        "         #x=ALL_Data['Date'][h]-math.trunc(ALL_Data['Date'][0]/100)*100 \n",
        "         x=ALL_Data['Date'][h]-i\n",
        "         if x >=0 and x <Every_hour :\n",
        "                yy=yy +ALL_Data['frequency'][h]    \n",
        "                Data_3hour['texte_cleaned'][i]=Data_3hour['texte_cleaned'][i]+  ALL_Data['texte_cleaned'][h]\n",
        "     Data_3hour['frequency'][i]=yy\n",
        "\n",
        "Data_3hour.head(20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>texte_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>3204</td>\n",
              "      <td>satellit imag show hurrican harvey begin reach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2537</td>\n",
              "      <td>rt nwshouston 4pm updat nhc show hurrican harv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2671</td>\n",
              "      <td>rt kingsth cant decid potu use hurricaneharvey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2017</td>\n",
              "      <td>rt rayrenato yall sin much spring break god pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1914</td>\n",
              "      <td>rt asiachloebrown sell flag target wyd nydaily...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2961</td>\n",
              "      <td>big thank kxannew share messag unt aaronjayjac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>484</td>\n",
              "      <td>que viagem local kroger chipsandsalsa tea boxw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1778</td>\n",
              "      <td>lmaooo cbsnew airbnb offer free hous hurrican ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>142</td>\n",
              "      <td>rt hifelicia fuck pleas elongreen pure essenc ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>4413</td>\n",
              "      <td>rt vp american harm way need prepar continu vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1560</td>\n",
              "      <td>rt jaketapp could instead spend money help vic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>9612</td>\n",
              "      <td>rt evanmcmurri houston swat offic carri mother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>8226</td>\n",
              "      <td>rt jaketapp could instead spend money help vic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>4263</td>\n",
              "      <td>rt miyashay offici say one check id statu shel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>232</td>\n",
              "      <td>rt thedweck almost climat chang cassieesmm lor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>563</td>\n",
              "      <td>rt uscg report harvey emerg must call number 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>6088</td>\n",
              "      <td>rt htxkel tf gonna thought send fuck money hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>2818</td>\n",
              "      <td>rt barackobama thank first respond peopl help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>1586</td>\n",
              "      <td>rt leegoldbergabc7 join us day give abc7ni the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.017083e+09</th>\n",
              "      <td>3706</td>\n",
              "      <td>rt ibealbertooooo cowboy 1m patriot 1m jj watt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             frequency                                      texte_cleaned\n",
              "2.017083e+09      3204  satellit imag show hurrican harvey begin reach...\n",
              "2.017083e+09      2537  rt nwshouston 4pm updat nhc show hurrican harv...\n",
              "2.017083e+09      2671  rt kingsth cant decid potu use hurricaneharvey...\n",
              "2.017083e+09      2017  rt rayrenato yall sin much spring break god pe...\n",
              "2.017083e+09      1914  rt asiachloebrown sell flag target wyd nydaily...\n",
              "2.017083e+09      2961  big thank kxannew share messag unt aaronjayjac...\n",
              "2.017083e+09       484  que viagem local kroger chipsandsalsa tea boxw...\n",
              "2.017083e+09      1778  lmaooo cbsnew airbnb offer free hous hurrican ...\n",
              "2.017083e+09       142  rt hifelicia fuck pleas elongreen pure essenc ...\n",
              "2.017083e+09      4413  rt vp american harm way need prepar continu vi...\n",
              "2.017083e+09      1560  rt jaketapp could instead spend money help vic...\n",
              "2.017083e+09      9612  rt evanmcmurri houston swat offic carri mother...\n",
              "2.017083e+09      8226  rt jaketapp could instead spend money help vic...\n",
              "2.017083e+09      4263  rt miyashay offici say one check id statu shel...\n",
              "2.017083e+09       232  rt thedweck almost climat chang cassieesmm lor...\n",
              "2.017083e+09       563  rt uscg report harvey emerg must call number 9...\n",
              "2.017083e+09      6088  rt htxkel tf gonna thought send fuck money hel...\n",
              "2.017083e+09      2818  rt barackobama thank first respond peopl help ...\n",
              "2.017083e+09      1586  rt leegoldbergabc7 join us day give abc7ni the...\n",
              "2.017083e+09      3706  rt ibealbertooooo cowboy 1m patriot 1m jj watt..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7CFJlGvu5JV"
      },
      "source": [
        "# every ...hour\n",
        "Data_3hour.to_excel(\"Harvey250_3hour.xlsx\",sheet_name='Sheet_name_1') \n",
        "#dayly or hourly\n",
        "#ALL_Data.to_excel(\"Harvey250_hourly.xlsx\",sheet_name='Sheet_name_1') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_s6LvyCpiK_"
      },
      "source": [
        "217_harvey_electrci\n",
        "11500harvey_electrci_any\n",
        "20000sample_harvey_1\n",
        "\n",
        "\n",
        "271_Irma_electrci_1\n",
        "55400Irma_electrci_any\n",
        "30000sample_irma\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_1dGMMudqL"
      },
      "source": [
        "Additional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxiNvWpGJJuH"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def cleaner(string):\n",
        "    \n",
        "    # Generate list of tokens\n",
        "    doc = nlp(string)\n",
        "    lemmas = [token.lemma_ for token in doc]    # Remove tokens that are not alphabetic \n",
        "    a_lemmas = [lemma for lemma in lemmas if lemma.isalpha() \n",
        "                 or lemma == '-PRON-']     # Print string after text cleaning\n",
        "    return ' '.join(a_lemmas)\n",
        "\n",
        "#data_tweet['text_cleaned'] = \\\n",
        "#                   data_tweet['text'].progress_apply(cleaner)\n",
        "\n",
        "#data_tweet['text_cleaned'] = \\\n",
        "#                   data_tweet['text'].progress_apply(cleaner)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJRl31JvIUCp"
      },
      "source": [
        "# Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w2NHVne7j25"
      },
      "source": [
        "**json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr_vxFMB7fe-",
        "outputId": "d5336a82-c8f2-4b25-f634-f77a01e50848"
      },
      "source": [
        "! sudo pip3 install simplejson\n",
        "import simplejson as json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 26.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 51kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 61kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 71kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 81kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 102kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 112kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 122kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 15.1MB/s \n",
            "\u001b[?25hInstalling collected packages: simplejson\n",
            "Successfully installed simplejson-3.17.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1jXMCfFIOBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "5bbd3889-a495-4236-a060-c64482acc3e4"
      },
      "source": [
        "with open('/content/drive/Shareddrives/MY Files/Tweeter Data/languages.json', 'r', encoding='utf-8') as json_file:\n",
        "    languages_dict = json.load(json_file)\n",
        "    \n",
        "names = []\n",
        "for idx, row in data_tweet.iterrows():\n",
        "    lang = row['lang']\n",
        "    if lang == 'und':\n",
        "        names.append(None)\n",
        "    elif lang == 'in':\n",
        "        name = languages_dict['id']['name']\n",
        "        names.append(name)\n",
        "    elif lang == 'iw':\n",
        "        name = languages_dict['he']['name']\n",
        "        names.append(name)\n",
        "    else:\n",
        "        name = languages_dict[lang]['name']\n",
        "        names.append(name)\n",
        "\n",
        "data_tweet['language'] = names\n",
        "data_tweet.drop(['lang'], axis=1, inplace=True)\n",
        "data_tweet.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf9b840d9ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shareddrives/MY Files/Tweeter Data/languages.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlanguages_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR4P92uR_dYi"
      },
      "source": [
        "data_tweet=data_tweet.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX7VIcREIvvQ"
      },
      "source": [
        "# user-locations \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiCcNolmAooX",
        "outputId": "f828360f-10d0-45f6-d7eb-e7138c6e7e64"
      },
      "source": [
        "!pip install country-converter\n",
        "import country_converter as coco\n",
        "\n",
        "# change codes to iso3 \n",
        "to_iso3_func = lambda x: coco.convert(names=x, to='iso3', not_found=None) \\\n",
        "                            if x is not None else x\n",
        "to_std_func = lambda x: coco.convert(names=x, to='name_short', not_found=None) \\\n",
        "                            if x is not None else x                          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting country-converter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/78/4c4c71c930f6ae2e213766c9de110b692a882670581e8602d0855f9446c4/country_converter-0.7.2.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from country-converter) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->country-converter) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->country-converter) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->country-converter) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->country-converter) (1.15.0)\n",
            "Building wheels for collected packages: country-converter\n",
            "  Building wheel for country-converter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for country-converter: filename=country_converter-0.7.2-cp37-none-any.whl size=51548 sha256=d12e5438dee76633e46dfed46579f6a684a820532ffbbefb78ffc6d114c05864\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/5e/12/6bd0fb7e1fa66794a41c4230d3d41679a4daf5815cd9fa2f2e\n",
            "Successfully built country-converter\n",
            "Installing collected packages: country-converter\n",
            "Successfully installed country-converter-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi-a7DskIuEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ac0a20-307f-4549-b8a5-1b55422ce723"
      },
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def geo_locator(user_location):\n",
        "    \n",
        "    # initialize geolocator\n",
        "    geolocator = Nominatim(user_agent='Tweet_locator')\n",
        "\n",
        "    if user_location is not None:\n",
        "        try :\n",
        "            # get location\n",
        "            location = geolocator.geocode(user_location, language='en')\n",
        "            # get coordinates\n",
        "            location_exact = geolocator.reverse(\n",
        "                        [location.latitude, location.longitude], language='en')\n",
        "            # get country codes\n",
        "            c_code = location_exact.raw['address']['country_code']\n",
        "\n",
        "            return c_code\n",
        "\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    else : \n",
        "        return None\n",
        "\n",
        "# apply geo locator to user-location\n",
        "loc = data_tweet['user_location'].progress_apply(geo_locator)\n",
        "data_tweet['user-country_code'] = loc\n",
        "\n",
        "# change codes to iso3 \n",
        "data_tweet['user-country_code'] = \\\n",
        "                    data_tweet['user-country_code'].apply(to_iso3_func)\n",
        "\n",
        "# create user-country column\n",
        "data_tweet['user-country'] = \\\n",
        "                    data_tweet['user-country_code'].apply(to_std_func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "  3%|▎         | 76/2733 [01:09<45:36,  1.03s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BDjwkYULGhb0",
        "outputId": "1e6d89a5-bf54-4e0e-a454-52ca83982a14"
      },
      "source": [
        "# drop old column\n",
        "#data_tweet.drop(['user_location','coordinates','user-country_code','place' ], axis=1, inplace=True)\n",
        "#data_tweet.drop(['user_location','user-country_code','place' ], axis=1, inplace=True)\n",
        "data_tweet['location'] = data_tweet['user-country'] \n",
        "data_tweet['location_code'] = data_tweet['user-country_code'] \n",
        "data_tweet.drop(['user_location','user-country','user-country_code' ], axis=1, inplace=True)\n",
        "data_tweet.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>language</th>\n",
              "      <th>location</th>\n",
              "      <th>location_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>905480659724103687</td>\n",
              "      <td>Wed Sep 06 17:19:46 +0000 2017</td>\n",
              "      <td>RT @MurphTWN: #DYK: Energy released by a #hurr...</td>\n",
              "      <td>8238</td>\n",
              "      <td>English</td>\n",
              "      <td>Canada</td>\n",
              "      <td>CAN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>904893643571380224</td>\n",
              "      <td>Tue Sep 05 02:27:11 +0000 2017</td>\n",
              "      <td>RT @ABC: Some shoreline communities that bore ...</td>\n",
              "      <td>88</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>901184978679205897</td>\n",
              "      <td>Fri Aug 25 20:50:16 +0000 2017</td>\n",
              "      <td>RT @WxComm: 3. Be kind to everyone you are dea...</td>\n",
              "      <td>2520</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>906477448145010688</td>\n",
              "      <td>Sat Sep 09 11:20:39 +0000 2017</td>\n",
              "      <td>This is horrible. https://t.co/K6mdgYflJS</td>\n",
              "      <td>2094</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>901834179125673985</td>\n",
              "      <td>Sun Aug 27 15:49:58 +0000 2017</td>\n",
              "      <td>RT @USANewsAgency: If you know someone in #Hou...</td>\n",
              "      <td>666</td>\n",
              "      <td>English</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ... location_code\n",
              "0  905480659724103687  ...           CAN\n",
              "1  904893643571380224  ...           USA\n",
              "2  901184978679205897  ...           USA\n",
              "3  906477448145010688  ...           USA\n",
              "4  901834179125673985  ...          None\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYn4neAkJLLw"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkKZkrqAJX8z"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4pU5WdfLmMT",
        "outputId": "e7b3b693-58bb-4f90-d1c8-93cf44d82cab"
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.12.5)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.0MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.1MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15736 sha256=35018121182b5282241503d5bd7c43994b8f11f6948585e0d8bd0d7e4d11ceeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7667 sha256=dc7836d39d151593df95c97dd71ca0edfa7b1ddc8a7417fc1136f1a232ca201e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: immutables, contextvars, sniffio, h11, hyperframe, hpack, h2, httpcore, hstspreload, rfc3986, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P03HJia_JTZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515a66cd-1fb9-403f-e736-c7c1f1cb7cdc"
      },
      "source": [
        "# select only not-null tweets not in English\n",
        "mask1 = data_tweet['text'].notnull()\n",
        "mask2 = data_tweet['language'] != 'English'\n",
        "df_masked = data_tweet[(mask1) & (mask2)]\n",
        "\n",
        "# split dataframe in x equal-size pieces\n",
        "data_tweet_splitted = np.array_split(df_masked, 150)\n",
        "\n",
        "def tweet_translation(df, idx):\n",
        "    \n",
        "    \"\"\" Translate tweets using googletrans \"\"\"\n",
        "    \n",
        "    from googletrans import Translator\n",
        "    \n",
        "    translator = Translator()\n",
        "    \n",
        "    try:\n",
        "        # translate raw tweet\n",
        "        trans = df['text'].apply(translator.translate, dest='en')\n",
        "        # create column extracting the translated text\n",
        "        df['text_english'] = trans.apply(lambda x: x.text)\n",
        "        # append to empty list\n",
        "        translations.append(df)\n",
        "        # save data in case error happens\n",
        "        #df.to_csv('Translations/translation_{}.csv'.format(idx))\n",
        "   \n",
        "    except Exception as e:  \n",
        "        print(e, ' -- at index ', idx)\n",
        "        \n",
        "translations = []\n",
        "for idx, df in enumerate(tqdm(data_tweet_splitted)):\n",
        "    tqdm._instances.clear()\n",
        "    tweet_translation(df, idx)\n",
        "    \n",
        "# concatenate the chunks into a single dataframe\n",
        "df_translations = pd.concat(translations)\n",
        "# join it with the old one\n",
        "df_english = data_tweet.join(df_translations['text_english'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 18/150 [00:00<00:18,  7.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "'NoneType' object has no attribute 'group'  -- at index  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:01<00:00, 133.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "MbnUS-ZFL1YS",
        "outputId": "1fe3cfab-8862-403d-dd05-dd2bf6910f2d"
      },
      "source": [
        "df_english.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time</th>\n",
              "      <th>text</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>language</th>\n",
              "      <th>location</th>\n",
              "      <th>location_code</th>\n",
              "      <th>text_cleaned</th>\n",
              "      <th>text_english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>905480659724103687</td>\n",
              "      <td>Wed Sep 06 17:19:46 +0000 2017</td>\n",
              "      <td>RT @MurphTWN: #DYK: Energy released by a #hurr...</td>\n",
              "      <td>8238</td>\n",
              "      <td>English</td>\n",
              "      <td>Canada</td>\n",
              "      <td>CAN</td>\n",
              "      <td>RT DYK energy release by a hurricane could if ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>904893643571380224</td>\n",
              "      <td>Tue Sep 05 02:27:11 +0000 2017</td>\n",
              "      <td>RT @ABC: Some shoreline communities that bore ...</td>\n",
              "      <td>88</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "      <td>RT some shoreline community that bear brunt of...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>901184978679205897</td>\n",
              "      <td>Fri Aug 25 20:50:16 +0000 2017</td>\n",
              "      <td>RT @WxComm: 3. Be kind to everyone you are dea...</td>\n",
              "      <td>2520</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "      <td>RT be kind to everyone -PRON- be deal w at the...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>906477448145010688</td>\n",
              "      <td>Sat Sep 09 11:20:39 +0000 2017</td>\n",
              "      <td>This is horrible. https://t.co/K6mdgYflJS</td>\n",
              "      <td>2094</td>\n",
              "      <td>English</td>\n",
              "      <td>United States</td>\n",
              "      <td>USA</td>\n",
              "      <td>this be horrible</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>901834179125673985</td>\n",
              "      <td>Sun Aug 27 15:49:58 +0000 2017</td>\n",
              "      <td>RT @USANewsAgency: If you know someone in #Hou...</td>\n",
              "      <td>666</td>\n",
              "      <td>English</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>RT if -PRON- know someone in Houston wake -PRO...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ... text_english\n",
              "0  905480659724103687  ...          NaN\n",
              "1  904893643571380224  ...          NaN\n",
              "2  901184978679205897  ...          NaN\n",
              "3  906477448145010688  ...          NaN\n",
              "4  901834179125673985  ...          NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACwTgqO7JjEg"
      },
      "source": [
        "*Text in english*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgnAQJWRJiI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "cfafbed9-213d-41de-ddd8-3ea1a7a02902"
      },
      "source": [
        "# replaces NaNs by Nones\n",
        "#df_english.where(pd.notnull(df_english), None, inplace=True)\n",
        "# add original English tweets to text_english by replacing Nones\n",
        "texts = []\n",
        "for idx, row in df_english.iterrows():\n",
        "    if row['text_english'] is None:\n",
        "        text = row['text']\n",
        "        texts.append(text)\n",
        "    else :\n",
        "        texts.append(row['text_english'])\n",
        "\n",
        "df_english['text_english'] = texts\n",
        "df_english.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3c36147b3ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# add original English tweets to text_english by replacing Nones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_english\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_english'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_english' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIjK9m8OJvLX"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2abu1G9JygM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6438b0-c6aa-480a-955a-af0d650e6511"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "df_sentiment = df_english.copy()\n",
        "\n",
        "# instantiate new SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "sentiment_scores = df_sentiment['text_cleaned'].progress_apply(\n",
        "                                                            sid.polarity_scores)\n",
        "sentiment = sentiment_scores.apply(lambda x: x['compound'])\n",
        "df_sentiment['sentiment'] = sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 1027.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENg9MDEgJ5Or"
      },
      "source": [
        "# finishing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUcPRjBAJ7NF"
      },
      "source": [
        "cols_order = ['text', 'language', 'location', 'location_code', \n",
        "              'location-coordinates', 'sentiment', 'text_english', \n",
        "              'text_cleaned', 'user-screen_name']df_final = df_sentiment[cols_order]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_uoq4OwKB2k"
      },
      "source": [
        "# Extra: a simple analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIfw3j7WKA-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c52ab668-a1cd-45e1-ac30-1e401235ba8e"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "countries_lang = pd.read_excel('/content/drive/Shareddrives/MY Files/Tweeter Data/countries_lang_full.xlsx', index_col=0)\n",
        "\n",
        "tweets_loc = df_sentiment.copy()\n",
        "\n",
        "# group tweets by location\n",
        "agg = {'text': 'count', 'sentiment': 'mean'}\n",
        "tweets_loc = tweets_loc.groupby('location').agg(agg)\n",
        "tweets_loc.sort_values(by='sentiment', ascending=False, inplace=True)\n",
        "tweets_loc = tweets_loc.rename(columns={'text':'count'})\n",
        "\n",
        "# get country codes\n",
        "codes = []\n",
        "for loc in tweets_loc.index:\n",
        "    code = countries_lang[countries_lang.Country_name==loc]['Country_code']\n",
        "    codes.append(code.values[0])\n",
        "tweets_loc['country_code'] = codes\n",
        "\n",
        "tweets_loc.reset_index(inplace=True)\n",
        "\n",
        "# Plotly\n",
        "fig = px.choropleth(tweets_loc, locations=\"country_code\", \n",
        "                    color='sentiment',\n",
        "                    hover_name='location', \n",
        "                    hover_data=['count'], \n",
        "                    color_continuous_scale='ice', scope='world') \n",
        "\n",
        "fig.update_layout(\n",
        "    title_text = \"Mean Twitter sentiment score by country\",\n",
        "    \n",
        "    geo=dict(showframe=False, showcoastlines=False, \n",
        "             projection_type='equirectangular'),\n",
        "    \n",
        "    annotations = [dict(x=-0.04, y=0.95, xref='paper', yref='paper',\n",
        "        text='Sentiment of Hurricane', \n",
        "        showarrow=False)]\n",
        ")\n",
        "\n",
        "fig.update_geos(resolution=110, showcountries=False, \n",
        "                lataxis_range=[-55, 90], lonaxis_range=[-180, 180])\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"219e58ae-9a4b-47a9-a8d6-703051b228c2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"219e58ae-9a4b-47a9-a8d6-703051b228c2\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '219e58ae-9a4b-47a9-a8d6-703051b228c2',\n",
              "                        [{\"coloraxis\": \"coloraxis\", \"customdata\": [[1], [7], [1]], \"geo\": \"geo\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>count=%{customdata[0]}<br>country_code=%{location}<br>sentiment=%{z}\", \"hovertext\": [\"Canada\", \"United States\", \"Afghanistan\"], \"locations\": [\"CAN\", \"USA\", \"AFG\"], \"name\": \"\", \"type\": \"choropleth\", \"z\": [0.2732, -0.08862857142857142, -0.5267]}],\n",
              "                        {\"annotations\": [{\"showarrow\": false, \"text\": \"Sentiment of Hurricane\", \"x\": -0.04, \"xref\": \"paper\", \"y\": 0.95, \"yref\": \"paper\"}], \"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"sentiment\"}}, \"colorscale\": [[0.0, \"rgb(3, 5, 18)\"], [0.09090909090909091, \"rgb(25, 25, 51)\"], [0.18181818181818182, \"rgb(44, 42, 87)\"], [0.2727272727272727, \"rgb(58, 60, 125)\"], [0.36363636363636365, \"rgb(62, 83, 160)\"], [0.45454545454545453, \"rgb(62, 109, 178)\"], [0.5454545454545454, \"rgb(72, 134, 187)\"], [0.6363636363636364, \"rgb(89, 159, 196)\"], [0.7272727272727273, \"rgb(114, 184, 205)\"], [0.8181818181818182, \"rgb(149, 207, 216)\"], [0.9090909090909091, \"rgb(192, 229, 232)\"], [1.0, \"rgb(234, 252, 253)\"]]}, \"geo\": {\"center\": {}, \"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"lataxis\": {\"range\": [-55, 90]}, \"lonaxis\": {\"range\": [-180, 180]}, \"projection\": {\"type\": \"equirectangular\"}, \"resolution\": 110, \"scope\": \"world\", \"showcoastlines\": false, \"showcountries\": false, \"showframe\": false}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Mean Twitter sentiment score by country\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('219e58ae-9a4b-47a9-a8d6-703051b228c2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXOZVyw9S6Gt"
      },
      "source": [
        "# LIWC\n",
        "\n",
        "**dictionary:**\n",
        "http://www.liwc.net/dictionaries/index.php/liwcdic/7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVPsUdIGS5nd"
      },
      "source": [
        "#!pip install liwc-text-analysis\n",
        "#from liwc import Liwc\n",
        "#liwc = Liwc('/content/drive/Shareddrives/MY Files/Tweeter Data/LIWC dictionary/LIWC2015-jfx.jar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb2xC2BwQEp5"
      },
      "source": [
        "# **bigram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tgy2FGjP8Bi"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import bigrams\n",
        "import collections\n",
        "from nltk.tokenize import regexp\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import docx\n",
        "import docx2txt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "result = docx2txt.process(\"C:/Users/JabV/Desktop/Web sceinec2020/Work 5 Data analysis/DAta Cleaned/News Monthly/All.docx\")\n",
        "\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    \"\"\"Remove special patterns - email, url, date etc.\"\"\"\n",
        "    email_regex = re.compile(r\"[\\w.-]+@[\\w.-]+\")\n",
        "    url_regex = re.compile(r\"(http|www)[^\\s]+\")\n",
        "    date_regex = re.compile(r\"[\\d]{2,4}[ -/:]*[\\d]{2,4}([ -/:]*[\\d]{2,4})?\") # a way to match date\n",
        "    ## remove\n",
        "    text = url_regex.sub(\"\", text)\n",
        "    text = email_regex.sub(\"\", text)\n",
        "    text = date_regex.sub(\"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "result1=remove_html(result)\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
        "    return no_punct\n",
        "\n",
        "\n",
        "result2=remove_punctuation(result1)\n",
        "\n",
        "#1 No tokenize\n",
        "#tokenized_text=result2.lower()\n",
        "\n",
        "#2 Tokenize\n",
        "word_tokenizer = regexp.WhitespaceTokenizer()\n",
        "tokenized_text = [word.lower() for word in word_tokenizer.tokenize(result2)]\n",
        "\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words=[w for w in text if w not in stopwords.words('english')]\n",
        "    return words\n",
        "\n",
        "result3=remove_stopwords(tokenized_text)\n",
        "\n",
        "\n",
        "\n",
        "result5=[result3]\n",
        "\n",
        "terms_bigram = [list(bigrams(x)) for x in result5]\n",
        "bigrams = list(itertools.chain(*terms_bigram))\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "#print(bigram_counts.most_common(5))\n",
        "\n",
        "\n",
        "\n",
        "# 5- table by panda\n",
        "bigram_df = pd.DataFrame(bigram_counts.most_common(20),\n",
        "                             columns=['bigram', 'count'])\n",
        "\n",
        "print(bigram_df)\n",
        "#6-  Visualize Networks of Bigrams\n",
        "\n",
        "# Create dictionary of bigrams and their counts\n",
        "d = bigram_df.set_index('bigram').T.to_dict('records')\n",
        "\n",
        "\n",
        "# Create network plot \n",
        "G = nx.Graph()\n",
        "\n",
        "# Create connections between nodes\n",
        "for k, v in d[0].items():\n",
        "    G.add_edge(k[0], k[1], weight=(v * 10))\n",
        "\n",
        "G.add_node(\"China\", weight=100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "pos = nx.spring_layout(G, k=2)\n",
        "\n",
        "# Plot networks\n",
        "nx.draw_networkx(G, pos,\n",
        "                 font_size=100,\n",
        "                 width=5,\n",
        "                 edge_color='grey',\n",
        "                 node_color='purple',\n",
        "                 with_labels = False,\n",
        "                 ax=ax)\n",
        "\n",
        "# Create offset labels\n",
        "for key, value in pos.items():\n",
        "    x, y = value[0]+.135, value[1]+.045\n",
        "    ax.text(x, y,\n",
        "            s=key,\n",
        "            bbox=dict(facecolor='red', alpha=0.25),\n",
        "            horizontalalignment='center', fontsize=13)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WghwTKT6Obz4"
      },
      "source": [
        "# **NEWS API**  (only past 20 days)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLoJ3uBKRWIu",
        "outputId": "a32ec33b-257e-4013-b946-cff93f896715"
      },
      "source": [
        "!pip install newsapi-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading https://files.pythonhosted.org/packages/de/9e/9050199ac7cbc755d1c49577fdaa5517901124b574264b3602a8b8028440/newsapi_python-0.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgNnfHvIOiL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d5e27a-2c9d-41be-b233-dfbec2f124ac"
      },
      "source": [
        "import pandas as pd\n",
        "from newsapi import NewsApiClient\n",
        "\n",
        "# Init\n",
        "newsapi = NewsApiClient(api_key='3446f68fc41745c0b6ad72e0bf2d7134')\n",
        "\n",
        "# /v2/top-headlines\n",
        "top_headlines = newsapi.get_top_headlines(q='bitcoin',\n",
        "                                         #sources='bbc-news,the-verge',\n",
        "                                          category='business',\n",
        "                                          language='en',\n",
        "                                          country='us')\n",
        "\n",
        "\n",
        "# /v2/everything\n",
        "all_articles = newsapi.get_everything(q='bitcoin',\n",
        "                                      sources='bbc-news,the-verge',\n",
        "                                      domains='bbc.co.uk,techcrunch.com',\n",
        "                                      from_param='2021-01-10',\n",
        "                                      to='2021-01-19',\n",
        "                                      language='en',\n",
        "                                      sort_by='relevancy',\n",
        "                                      page=2)\n",
        "\n",
        "\n",
        "# /v2/sources\n",
        "sources = newsapi.get_sources()\n",
        "\n",
        "\n",
        "## Let's make a request to get live top headlines in the US\n",
        "## right now. We'll use the /top-headlines endpoint for this.\n",
        "import requests\n",
        "url = ('http://newsapi.org/v2/top-headlines?'\n",
        "       'country=us&'\n",
        "       'apiKey=3446f68fc41745c0b6ad72e0bf2d7134')\n",
        "response = requests.get(url)\n",
        "print(response.json())\n",
        "\n",
        "\n",
        "## If you want headlines just from a specific source,\n",
        "##for example BBC News, we can do that too.\n",
        "\n",
        "# News resources: https://newsapi.org/sources \n",
        "\n",
        "import requests\n",
        "url = ('http://newsapi.org/v2/top-headlines?'\n",
        "       'sources=bbc-news&'\n",
        "       'apiKey=3446f68fc41745c0b6ad72e0bf2d7134')\n",
        "response = requests.get(url)\n",
        "print(response.json())\n",
        "\n",
        "\n",
        "\n",
        "## I want to search for news articles that mention a\n",
        "## specific topic or keyword\n",
        "\n",
        "import requests\n",
        "\n",
        "url = ('http://newsapi.org/v2/everything?'\n",
        "       'q=Apple&'\n",
        "       'from=2020-05-19&'\n",
        "       'sortBy=popularity&'\n",
        "       'apiKey=3446f68fc41745c0b6ad72e0bf2d7134')\n",
        "\n",
        "response =requests.get(url)\n",
        "\n",
        "print(response.json())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'status': 'ok', 'totalResults': 38, 'articles': [{'source': {'id': None, 'name': 'AL.com'}, 'author': 'Creg Stephenson | cstephenson@al.com', 'title': 'Senior Bowl 2021: 10 players who made big impressions this week - AL.com', 'description': 'NFL draft showcase took place Saturday in Mobile', 'url': 'https://www.al.com/sports/2021/01/senior-bowl-2021-10-players-who-made-big-impressions-this-week.html', 'urlToImage': 'https://www.al.com/resizer/j_8LiFQEssVN5HePtIjxDBcj1Ic=/1280x0/smart/cloudfront-us-east-1.images.arcpublishing.com/advancelocal/BIJMG6B4INC5LADXNSRETRA5HE.jpg', 'publishedAt': '2021-01-31T00:07:00Z', 'content': 'What might have been the most-important Reeses Senior Bowl week in the games 71-year history wrapped up Saturday in Mobile.\\r\\nWith the NFL Combine set to include no in-person interaction between playe… [+4185 chars]'}, {'source': {'id': 'nbc-news', 'name': 'NBC News'}, 'author': 'Laura Strickler, Dennis Romero', 'title': 'FEMA is deploying or supporting vaccination sites in 11 states - NBC News', 'description': 'After President Biden ordered \"a wartime effort\" on vaccination, FEMA said it\\'s deploying or supporting vaccination sites in 11 states.', 'url': 'https://www.nbcnews.com/news/us-news/fema-deploying-or-supporting-vaccination-sites-11-states-n1256280', 'urlToImage': 'https://media3.s-nbcnews.com/j/newscms/2021_04/3446359/210130-vaccine-site-arizona-al-1514_d874a43b3a913ab9016ab57e6198a489.nbcnews-fp-1200-630.jpg', 'publishedAt': '2021-01-30T22:33:00Z', 'content': 'The Federal Emergency Management Agency is deploying or supporting vaccination sites in at least 11 states after President Joe Biden ordered the government to get on a war footing in his mission to v… [+1669 chars]'}, {'source': {'id': None, 'name': 'New York Post'}, 'author': 'Dean Balsamini', 'title': \"Lenny Dykstra rips 'vultures' for trolling Steve Cohen on Twitter - New York Post \", 'description': 'Lenny Dykstra came out swinging Saturday against the “vultures” that forced billionaire Mets owner Steve Cohen to bench his Twitter account amid the GameStop tumult. “He should ha…', 'url': 'https://nypost.com/2021/01/30/lenny-dykstra-rips-vultures-for-trolling-steve-cohen-on-twitter/', 'urlToImage': 'https://nypost.com/wp-content/uploads/sites/2/2021/01/Lenny-Dykstra.jpg?quality=90&strip=all&w=1200', 'publishedAt': '2021-01-30T22:27:00Z', 'content': 'Lenny Dykstra came out swinging Saturday against the “vultures” that forced billionaire Mets owner Steve Cohen to bench his Twitter account amid the GameStop tumult.\\r\\n“He should have never gotten on … [+1082 chars]'}, {'source': {'id': None, 'name': 'nj.com'}, 'author': 'Len Melisurgo | NJ Advance Media for NJ.com', 'title': 'N.J. weather: Winter storm warnings issued with heavy wind-driven snow, dangerous driving conditions expected - NJ.com', 'description': 'Forecasters are warning of hazardous driving conditions Sunday night and throughout the day on Monday.', 'url': 'https://www.nj.com/weather/2021/01/nj-weather-winter-storm-warnings-issued-with-heavy-wind-driven-snow-dangerous-driving-conditions-expected.html', 'urlToImage': 'https://www.nj.com/resizer/5dbBXnsFVoQEVZqD39X7YQtVia8=/1280x0/smart/cloudfront-us-east-1.images.arcpublishing.com/advancelocal/JKUAIRMBHZFUXIHGZIUXJPVCII.png', 'publishedAt': '2021-01-30T22:07:00Z', 'content': 'The National Weather Service has upgraded its winter storm watches to winter storm warnings in advance of a slow-moving coastal storm that could dump more than a foot of snow on much of New Jersey an… [+4210 chars]'}, {'source': {'id': 'engadget', 'name': 'Engadget'}, 'author': '', 'title': 'Apple just paid a record $25 million to buy a Sundance movie - Engadget', 'description': \"Apple has paid $25 million to buy the movie 'CODA' — a record amount for a Sundance Film Festival deal.\", 'url': 'https://www.engadget.com/apple-buys-coda-sundance-movie-for-record-price-212335293.html', 'urlToImage': 'https://o.aolcdn.com/images/dims?resize=1200%2C630&crop=1200%2C630%2C0%2C0&quality=95&image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2021-01%2F3e44b590-633c-11eb-bdda-1638145bdb29&client=amp-blogside-v2&signature=492ffb13628be46e08e2f5f1dedc3292d7866df1', 'publishedAt': '2021-01-30T21:24:22Z', 'content': 'The purchase reportedly came about through a bidding war with Amazon. The Prime Video operator was eager to buy CODA, Variety said, but might not have had the room to release the title in 2021 given … [+1024 chars]'}, {'source': {'id': None, 'name': 'CNET'}, 'author': 'Ian Sherr', 'title': \"Reddit makes AMC, GameStop stock go wild: An 'insane' 'Ponzi scheme' 'train wreck' - CNET\", 'description': \"Social media-fueled investors are hitting multimillion-dollar paydays as they battle Wall Street over GameStop's stock. Experts say it can't last.\", 'url': 'https://www.cnet.com/news/reddit-makes-amc-gamestop-stock-go-wild-this-insane-ponzi-scheme-is-a-train-wreck/', 'urlToImage': 'https://cnet3.cbsistatic.com/img/L18zNxyzKnUqw3hvrJDDlbYf7fQ=/1200x630/left/bottom/2020/12/16/4432181a-9466-4891-b9b1-76579ded7c8a/breaking-the-piggy-bank-stimulus-check-cash-money-savings-debt-personal-finance-069-2.jpg', 'publishedAt': '2021-01-30T21:20:00Z', 'content': \"GameStop shareholders are watching piles of cash come in. But for how long?\\r\\nGetty Images\\r\\nMany of today's young adults spent their youth in\\xa0GameStop\\xa0stores. They lined up for launches. They bought a… [+8653 chars]\"}, {'source': {'id': 'cnn', 'name': 'CNN'}, 'author': 'Jason Hoffman, CNN', 'title': 'Plan to vaccinate Guantanamo Bay detainees against Covid-19 has been paused - CNN', 'description': 'An earlier plan to give Guantanamo Bay detainees the Covid-19 vaccine has been paused as of Saturday, according to a US Pentagon official.', 'url': 'https://www.cnn.com/2021/01/30/politics/guantanamo-bay-detainees-covid-19-vaccine-paused/index.html', 'urlToImage': 'https://cdn.cnn.com/cnnnext/dam/assets/190306104052-guantanamo-bay-super-tease.jpg', 'publishedAt': '2021-01-30T21:14:00Z', 'content': '(CNN)An earlier plan to give Guantanamo Bay detainees the Covid-19 vaccine has been paused as of Saturday, according to a US Pentagon official. \\r\\nPentagon press secretary John Kirby said in a Saturda… [+1453 chars]'}, {'source': {'id': None, 'name': 'CNBC'}, 'author': 'Abigail Johnson Hess', 'title': 'Russian anti-corruption group founded by Navalny calls for Biden to sanction Putin allies in letter - CNBC', 'description': 'The call for sanctions comes after tens of thousands of demonstrators protested the poisoning and arrest of Navalny by Russian officials.', 'url': 'https://www.cnbc.com/2021/01/30/navalny-anti-corruption-group-calls-on-biden-to-sanction-putin-allies.html', 'urlToImage': 'https://image.cnbcfm.com/api/v1/image/106829273-1611584784959-gettyimages-1230747773-4c4a5004.jpeg?v=1612036997', 'publishedAt': '2021-01-30T21:14:00Z', 'content': \"Russian opposition leader Alexei Navalny's Anti-Corruption Foundation, in a letter addressed to President Joe Biden, is calling for the United States to impose sanctions on dozens of Russian oligarch… [+2297 chars]\"}, {'source': {'id': None, 'name': 'New York Post'}, 'author': 'Mary Kay Linge', 'title': \"MTA worker who attended Capitol riot ID'd as Proud Boy, faces conspiracy charge: DOJ - New York Post \", 'description': 'The MTA worker arrested this month for his part in the Jan. 6 storming of the US Capitol is a member of the Proud Boys, federal officials say — and is now facing more serious charges of consp…', 'url': 'https://nypost.com/2021/01/30/capitol-riot-mta-worker-idd-as-proud-boy-faces-conspiracy-charge/', 'urlToImage': 'https://nypost.com/wp-content/uploads/sites/2/2021/01/will-pepe-proud-boys-1.jpg?quality=90&strip=all&w=1200', 'publishedAt': '2021-01-30T21:07:00Z', 'content': 'The MTA worker arrested this month for his part in the Jan. 6 storming of the US Capitol is a member of the Proud Boys, federal officials say — and is now facing more serious charges of conspiracy an… [+1148 chars]'}, {'source': {'id': None, 'name': 'Yahoo Entertainment'}, 'author': 'Justina Lee', 'title': 'A Reddit Army Descends on Hedge Funds Chained by Risk Models - Yahoo Finance', 'description': '(Bloomberg) -- A hellish week for hedge funds will be remembered for how much damage Reddit traders caused by chasing a handful of the most-shorted names in ...', 'url': 'https://finance.yahoo.com/news/reddit-army-descends-hedge-funds-210000613.html', 'urlToImage': 'https://s.yimg.com/uu/api/res/1.2/_tQyYgoz6W0XTcPS_5Wwcw--~B/aD00NjU7dz04OTY7YXBwaWQ9eXRhY2h5b24-/https://media.zenfs.com/en/bloomberg_markets_842/15223da2c3a4c990ededf5e3e2ed4963', 'publishedAt': '2021-01-30T21:00:00Z', 'content': '(Bloomberg) -- A hellish week for hedge funds will be remembered for how much damage Reddit traders caused by chasing a handful of the most-shorted names in the $43 trillion U.S. stock market.\\r\\nBut j… [+3828 chars]'}, {'source': {'id': None, 'name': 'New York Times'}, 'author': 'Zach Montague', 'title': 'The C.D.C. Issues Mask Mandate for Domestic Travel - The New York Times', 'description': 'A spokesman for the agency said that the order relied heavily on voluntary action to enforce the mandate.', 'url': 'https://www.nytimes.com/2021/01/30/world/cdc-mask-mandate.html', 'urlToImage': 'https://static01.nyt.com/images/2021/01/30/world/30virus-briefing-mask-mandate-1/30virus-briefing-mask-mandate-1-facebookJumbo.jpg', 'publishedAt': '2021-01-30T20:55:00Z', 'content': 'A similar order was proposed during the Trump administration, but the White House Coronavirus Task Force, led by Vice President Mike Pence, blocked the effort.\\r\\nRequiring masks on our transportation … [+1260 chars]'}, {'source': {'id': None, 'name': 'KTVZ'}, 'author': 'KTVZ news sources', 'title': 'Oregon reports 19 more COVID-19 deaths, 2 in Deschutes County - KTVZ', 'description': 'There are 19 new COVID-19 related deaths in Oregon, including two in Deschutes County, raising the state’s death toll to 1,957, the Oregon Health Authority reported Saturday.', 'url': 'https://ktvz.com/news/coronavirus/2021/01/30/oregon-reports-19-more-covid-19-deaths-2-in-deschutes-county/', 'urlToImage': 'https://ktvz.b-cdn.net/2020/11/Coronavirus-COVID-19-MGN-1113.jpg', 'publishedAt': '2021-01-30T20:50:28Z', 'content': 'Gov. Brown directs OHA to release more details on deaths weekly\\r\\nPORTLAND, Ore. (KTVZ) -- There are 19 new COVID-19 related deaths in Oregon, including two in Deschutes County, raising the states dea… [+12416 chars]'}, {'source': {'id': 'fox-news', 'name': 'Fox News'}, 'author': 'Paul Steinhauser', 'title': \"Republicans in key battlegrounds push to tighten voting rules in wake of Trump's defeat - Fox News\", 'description': 'Republican state lawmakers in three battleground states where\\xa0President Biden narrowly edged Donald Trump in November’s presidential election\\xa0are pushing to tighten voting restrictions on mail-in balloting in future contests.', 'url': 'https://www.foxnews.com/politics/republicans-key-battlegrounds-push-voting-restrictions-trump', 'urlToImage': 'https://static.foxnews.com/foxnews.com/content/uploads/2020/11/AP20308557453445.jpg', 'publishedAt': '2021-01-30T20:46:45Z', 'content': 'Republican state lawmakers in three battleground states where\\xa0President Biden narrowly edged Donald Trump in Novembers presidential election\\xa0are pushing to tighten voting restrictions on mail-in ball… [+4650 chars]'}, {'source': {'id': 'bloomberg', 'name': 'Bloomberg'}, 'author': None, 'title': 'Faced With a Vaccine Emergency, the EU Made an Enemy of Everyone - Bloomberg', 'description': None, 'url': 'https://www.bloomberg.com/tosv2.html?vid=&uuid=4e63a180-635e-11eb-8505-192ebd536e49&url=L25ld3MvYXJ0aWNsZXMvMjAyMS0wMS0zMC9mYWNlZC13aXRoLWEtdmFjY2luZS1lbWVyZ2VuY3ktdGhlLWV1LW1hZGUtYW4tZW5lbXktb2YtZXZlcnlvbmU=', 'urlToImage': None, 'publishedAt': '2021-01-30T20:35:00Z', 'content': \"To continue, please click the box below to let us know you're not a robot.\"}, {'source': {'id': None, 'name': 'Vox'}, 'author': 'Anya van Wagtendonk', 'title': 'Alex Jones and Publix heir Julie Jenkins Fancelli helped fund Trump’s rally preceding the Capitol riot - Vox.com', 'description': 'According to the Wall Street Journal, Alex Jones asked for a speaking slot in exchange for his contribution; Julie Jenkins Fancelli reportedly helped pick the event coordinator. Their contributions were part of $86 million Trump and Republicans raised followi…', 'url': 'https://www.vox.com/2021/1/30/22257893/alex-jones-publix-heiress-julie-jenkins-fancelli-fund-trump-rally-capitol-riot', 'urlToImage': 'https://cdn.vox-cdn.com/thumbor/KiSvmVe21YMmGViLglzZhFdGVXY=/0x651:7200x4421/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/22270285/GettyImages_1294968816.jpg', 'publishedAt': '2021-01-30T20:30:00Z', 'content': 'A Wall Street Journal investigation has found a number of key allies of former President Donald Trump including far-right media personality Alex Jones and Julie Jenkins Fancelli, heir to the Publix s… [+5705 chars]'}, {'source': {'id': 'the-washington-post', 'name': 'The Washington Post'}, 'author': 'Joel Achenbach, Ariana Eunjung Cha', 'title': 'Coronavirus mutations add urgency to vaccination effort as experts warn of long battle ahead - Washington Post', 'description': '‘We’re very worried’: New research shows vaccines are less effective against highly transmissible variants.', 'url': 'https://www.washingtonpost.com/health/covid-mutations-herd-immunity/2021/01/30/0741722e-627c-11eb-9430-e7c77b5b0297_story.html', 'urlToImage': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/LO34DSTDFEI6XEDBA6V4YH4SFE.jpg&w=1440', 'publishedAt': '2021-01-30T20:17:00Z', 'content': 'The mutation-laden variants are on the move, and that includes one first identified in South Africa and confirmed in a Baltimore-area adult, Maryland Gov. Larry Hogan (R) said Saturday. It was the th… [+11642 chars]'}, {'source': {'id': 'fox-news', 'name': 'Fox News'}, 'author': 'Ryan Gaydos', 'title': 'Deshaun Watson removes Texans references from social media profiles amid tension with franchise - Fox News', 'description': 'Deshaun Watson raised eyebrows Saturday when he appeared to remove any references to the Houston Texans from his social media profiles amid growing tension between him and the organization.', 'url': 'https://www.foxnews.com/sports/deshaun-watson-removes-texans-references-social-media', 'urlToImage': 'https://static.foxnews.com/foxnews.com/content/uploads/2019/10/NFL-Deshaun-Watson3.jpg', 'publishedAt': '2021-01-30T20:08:39Z', 'content': 'Deshaun Watson raised eyebrows Saturday when he appeared to remove any references to the Houston Texans from his social media profiles amid growing tension between him and the organization.\\r\\nNow, Wat… [+1291 chars]'}, {'source': {'id': None, 'name': 'ComicBook.com'}, 'author': 'Tyler Fischer', 'title': 'New PS5 and Xbox Series X Stock Update Has Bad News Only - ComicBook.com', 'description': \"The PS5 and Xbox Series X are nearly impossible to find right now, and it sounds like this won't be changing anytime soon. The first month of 2021 is almost over, and while GameStop, Amazon, Best Buy, Target, Walmart, and more all released new stock this mont…\", 'url': 'https://comicbook.com/gaming/news/ps5-xbox-series-x-restock-buy-order-stock-2021-update/', 'urlToImage': 'https://media.comicbook.com/2020/05/ps5-xbox-series-x-1218497-1280x0.jpeg', 'publishedAt': '2021-01-30T19:41:00Z', 'content': \"The PS5 and Xbox Series X are nearly impossible to find right now, and it sounds like this won't be changing anytime soon. The first month of 2021 is almost over, and while GameStop, Amazon, Best Buy… [+1852 chars]\"}, {'source': {'id': None, 'name': 'Yahoo Entertainment'}, 'author': 'Lyndsey Parker', 'title': \"Grammy-nominated electronic artist Sophie dead at 34 after 'terrible accident' - Yahoo Entertainment\", 'description': '\"Sophie was a pioneer of a new sound, one of the most influential artists in the last decade. Not only for ingenious production and creativity but also for...', 'url': 'https://www.yahoo.com/entertainment/trailblazing-electronic-artist-sophie-dead-at-34-after-terrible-accident-190953723.html', 'urlToImage': 'https://s.yimg.com/os/creatr-uploaded-images/2021-01/0afcfed0-632e-11eb-9ffe-4d27d8847d65', 'publishedAt': '2021-01-30T19:09:00Z', 'content': 'Sophie (Photo: Transgressive Records)\\r\\nThe electronic music community was shaken Saturday morning by the news that Sophie, a trailblazing experimental pop artist and producer whod worked with Madonna… [+7321 chars]'}, {'source': {'id': 'politico', 'name': 'Politico'}, 'author': 'Ben Leonard', 'title': \"Marjorie Taylor Greene claims Trump's backing amid intra-GOP debate over her fitness to serve - POLITICO\", 'description': 'The purported endorsement comes after the former president met with House Minority Leader Kevin McCarthy.', 'url': 'https://www.politico.com/news/2021/01/30/marjorie-taylor-greene-trump-support-463996', 'urlToImage': 'https://static.politico.com/b0/62/3ab434974c39849d24e12774af3a/210120-marjorie-taylor-greene-trump-773.jpg', 'publishedAt': '2021-01-30T19:01:00Z', 'content': 'A spokesperson for Trump declined to comment or elaborate on the former presidents call with the Georgia Republican. The spokesman for Greenes House office, Nick Dyer, did not immediately respond to … [+3023 chars]'}]}\n",
            "{'status': 'ok', 'totalResults': 10, 'articles': [{'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': 'Hong Kong residents now eligible for special UK visa', 'description': 'From Sunday, those eligible can apply for a special UK visa using a smartphone app.', 'url': 'http://www.bbc.co.uk/news/uk-55847572', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/16442/production/_116720219_gettyimages-1219407768.jpg', 'publishedAt': '2021-01-31T02:22:22.2469536Z', 'content': 'media captionWhat is the BNO visa for Hong Kongers?\\r\\nA visa scheme to allow Hong Kong residents to come to the UK opens on Sunday, with some 300,000 people expected to apply. \\r\\nThe visa, which is ope… [+5264 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC Sport', 'title': 'Rashford racially abused on social media', 'description': 'Manchester United forward Marcus Rashford says he was subjected to \"humanity and social media at its worst\" after receiving racist abuse on Saturday night.', 'url': 'http://www.bbc.co.uk/sport/football/55872681', 'urlToImage': 'https://ichef.bbci.co.uk/live-experience/cps/624/cpsprodpb/D6E6/production/_116741055_gettyimages-1299479024.jpg', 'publishedAt': '2021-01-31T01:07:22.7068115Z', 'content': 'Manchester United drew 0-0 with Arsenal on Saturday\\r\\nManchester United forward Marcus Rashford says he was subjected to \"humanity and social media at its worst\" after receiving racist abuse on Saturd… [+2597 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"'Hospitals can't take our Covid patients'\", 'description': \"Lebanon's hospitals are turning away patients as the country buckles under Covid and economic collapse.\", 'url': 'http://www.bbc.co.uk/news/world-middle-east-55861948', 'urlToImage': 'https://ichef.bbci.co.uk/images/ic/400xn/p095k34j.jpg', 'publishedAt': '2021-01-31T00:52:20.3639639Z', 'content': 'First it was an economic collapse, then the Beirut blast, and now coronavirus.\\r\\nLebanon has seen a record number of infections and deaths in recent weeks after the authorities relaxed restrictions ov… [+215 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': 'India protests: Internet cut to hunger-striking farmers in Delhi', 'description': 'Tensions are rising in Delhi where thousands of farmers are demanding agriculture reforms be repealed.', 'url': 'http://www.bbc.co.uk/news/world-asia-india-55872480', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/1E67/production/_116738770_gettyimages-1230866035.jpg', 'publishedAt': '2021-01-30T22:52:30.2535814Z', 'content': 'image copyrightGetty Images\\r\\nimage captionThousands of farmers blocked a road in Ghazipur near Delhi on Saturday\\r\\nIndia has suspended mobile internet services in three areas around the capital, Delhi… [+2987 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"Central African Republic's capital in 'apocalyptic situation' as rebels close in\", 'description': 'A former prime minister says there is daily fighting as rebel forces encircle Bangui.', 'url': 'http://www.bbc.co.uk/news/world-africa-55872485', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/CEA8/production/_116740925_gettyimages-1230751392.jpg', 'publishedAt': '2021-01-30T22:52:27.3480524Z', 'content': 'image copyrightGetty Images\\r\\nimage captionUN peacekeepers from Rwanda are manning checkpoints on roads around Bangui\\r\\nThe situation in the Central African Republic\\'s (CAR) capital of Bangui is \"apoca… [+2634 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"'They're coming for us' - right-wing media on Biden's week\", 'description': 'After four years of cheerleading, conservative pundits have switched tack with Biden in their sights.', 'url': 'http://www.bbc.co.uk/news/world-us-canada-55845763', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/17254/production/_116740849_foxnews.jpg', 'publishedAt': '2021-01-30T22:52:24.6281688Z', 'content': \"By Tara McKelveyBBC White House reporter\\r\\nimage copyrightGetty Images\\r\\nPresident Biden may have called for unity but he's also trying to quickly dismantle Trump's legacy. How has his busy first full … [+7752 chars]\"}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"Covid: EU 'made a mistake' over vaccines, Gove says\", 'description': 'The Cabinet Office minister says he is \"confident\" the UK can continue with its planned jabs rollout.', 'url': 'http://www.bbc.co.uk/news/uk-55873288', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/2BB9/production/_116739111_pa-56891208.jpg', 'publishedAt': '2021-01-30T18:07:26.3639074Z', 'content': 'media captionGove: EU didn\\'t consult us or our friends in Dublin before triggering Article 16\\r\\nThe European Union recognised it \"made a mistake\" in triggering an emergency provision in the Brexit dea… [+5578 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"EU 'fiasco' on N Ireland heaps pressure on Commission\", 'description': \"Suspending part of the Brexit deal added to anger over the EU's Covid vaccine roll-out policy.\", 'url': 'http://www.bbc.co.uk/news/world-europe-55872763', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/9B0D/production/_116739693_854f61f8-f674-4a2a-945a-32f3c77cd538.jpg', 'publishedAt': '2021-01-30T17:52:26.3008769Z', 'content': 'Katya AdlerEurope editor@BBCkatyaadleron Twitter\\r\\nimage captionWill Ursula von der Leyen come under more pressure to resign?\\r\\n\"Misjudgement\", \"mismanagement\", \"blunder\"... and words that were far, fa… [+7116 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': \"Russian billionaire Arkady Rotenberg says 'Putin Palace' is his\", 'description': 'Businessman Arkady Rotenberg says he owns the vast property at the centre of a Russian controversy.', 'url': 'http://www.bbc.co.uk/news/world-europe-55872249', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/124DD/production/_116737947_gettyimages-1207611694.jpg', 'publishedAt': '2021-01-30T14:37:20.9889279Z', 'content': 'image copyrightTass via Getty Images\\r\\nimage captionMr Rotenberg (right) is a close associate of Mr Putin (left) through business and friendship\\r\\nRussian oligarch Arkady Rotenberg says he is the owner… [+2015 chars]'}, {'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'BBC News', 'title': 'Covid-19: France closes borders to most non-EU travel', 'description': 'Only essential travel from outside the bloc will be allowed from Sunday, but a lockdown is resisted.', 'url': 'http://www.bbc.co.uk/news/world-europe-55863069', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/D5CD/production/_116733745_0c29c7cb-0543-4759-a957-33e71cfa9d4a.jpg', 'publishedAt': '2021-01-29T22:37:19.7294163Z', 'content': 'image captionNon-EU travellers are currently required to test negative and self-isolate on arrival\\r\\nFrench PM Jean Castex has announced tough new Covid-19 border restrictions, but has again resisted … [+4090 chars]'}]}\n",
            "{'status': 'error', 'code': 'parameterInvalid', 'message': 'You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2020-12-30, but you have requested 2020-05-19. You may need to upgrade to a paid plan.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB4mqdAXOn6q"
      },
      "source": [
        "# **Google Trend**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZGj_WoiPb6R"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from pytrends.request import TrendReq\n",
        "pytrend = TrendReq()\n",
        "# interest Word\n",
        "pytrend.build_payload(kw_list=['Covid-19'])\n",
        "# in each country\n",
        "pytrend.interest_by_region()\n",
        "df = pytrend.interest_by_region()\n",
        "df.head()\n",
        "#df.reset_index().plot(x='geoName', y='Taylor Swift', figsize=(120, 10), kind ='bar')\n",
        "#plt.plot(df)\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#Daily Search Trends\n",
        "# Get Google Hot Trends data\n",
        "df = pytrend.trending_searches(pn='united_states')\n",
        "df.head()\n",
        "#Today\n",
        "df = pytrend.today_searches(pn='US')\n",
        "\n",
        "\n",
        "# Get Google Top Charts\n",
        "df = pytrend.top_charts(2019, hl='en-US', tz=300, geo='GLOBAL')\n",
        "df.head()\n",
        "\n",
        "# Get Google Keyword Suggestions\n",
        "keywords = pytrend.suggestions(keyword='Mercedes Benz')\n",
        "df = pd.DataFrame(keywords)\n",
        "df.drop(columns= 'mid')   # This column makes no sense\n",
        "\n",
        "\n",
        "\n",
        "# Related Queries, returns a dictionary of dataframes\n",
        "pytrend.build_payload(kw_list=['Coronavirus'])\n",
        "#related_queries = pytrend.related_queries()\n",
        "#related_queries.values()\n",
        "\n",
        "# Related Topics, returns a dictionary of dataframes\n",
        "related_topic = pytrend.related_topics()\n",
        "related_topic.values()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzSBi7sgPNV9"
      },
      "source": [
        "** over time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9GIzUOOx6V"
      },
      "source": [
        "####################   Input From Excel  ##############\n",
        "#import pandas as pd\n",
        "#file = 'example.xlsx'\n",
        "# Load spreadsheet\n",
        "#xl = pd.ExcelFile(file)\n",
        "# Print the sheet names\n",
        "#print(xl.sheet_names)\n",
        "# Load a sheet into a DataFrame by name: df1\n",
        "#df1 = xl.parse('Sheet1')\n",
        "\n",
        "#######################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pytrends.request import TrendReq\n",
        "pytrends = TrendReq()\n",
        "\n",
        "\n",
        "#Build Payload\n",
        "kw_list = ['Covid-19', 'Corona Virus', 'Corona', 'Covid 19', 'epidemic']\n",
        "#d=pytrends.suggestions('Covid')\n",
        "\n",
        "\n",
        "pytrends.build_payload(kw_list, cat=0, timeframe='today 3-m', geo='US-VA', gprop='')\n",
        "\n",
        "\n",
        "#Find Cat in https://github.com/pat310/google-trends-api/wiki/Google-Trends-Categories\n",
        "#Time Specific dates, 'YYYY-MM-DD YYYY-MM-DD' example '2016-12-14 2017-01-25'\n",
        "#GEO  'GB-ENG', 'US-AL'  'FR, MX, GB'  serach in  https://en.wikipedia.org/wiki/ISO_3166-2\n",
        "# timeframe='today 3-m','today 3-d','today 3-H','today 3-y'\n",
        "#gprop='' can be images, news, youtube or froogle \n",
        "########################\n",
        "\n",
        "\n",
        "# interest Word\n",
        "#pytrends.build_payload(kw_list=['Covid-19'])\n",
        "df =pytrends.interest_over_time()\n",
        "#plt.plot(df)\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############# Save To Excel ############################\n",
        "# Install \n",
        "# Specify a writer\n",
        "writer = pd.ExcelWriter('example.xlsx', engine='xlsxwriter') \n",
        "# Write your DataFrame to a file     \n",
        "df.to_excel(writer, 'Sheet1')\n",
        "# Save the result \n",
        "writer.save()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38DAtDgTVt1n"
      },
      "source": [
        "# gmt gEOGRPGY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFFTVaHFWBOW",
        "outputId": "14b2a2ea-5a37-4c49-b85a-bacf5e5a4e3c"
      },
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local\n",
        "!conda update conda -y -q\n",
        "!conda config --prepend channels conda-forge\n",
        "!conda install -q -y --prefix /usr/local python=3.8 pygmt\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "os.environ[\"GMT_LIBRARY_PATH\"]=\"/usr/local/lib\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-07 06:51:01--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94235922 (90M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  89.87M   250MB/s    in 0.4s    \n",
            "\n",
            "2021-03-07 06:51:01 (250 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [94235922/94235922]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2020.10.14=0\n",
            "    - certifi==2020.6.20=pyhd3eb1b0_3\n",
            "    - cffi==1.14.3=py38h261ae71_2\n",
            "    - chardet==3.0.4=py38h06a4308_1003\n",
            "    - conda-package-handling==1.7.2=py38h03888b9_0\n",
            "    - conda==4.9.2=py38h06a4308_0\n",
            "    - cryptography==3.2.1=py38h3c74f83_1\n",
            "    - idna==2.10=py_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20191231=h14c3975_1\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1h=h7b6447c_0\n",
            "    - pip==20.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.20=py_2\n",
            "    - pyopenssl==19.1.0=pyhd3eb1b0_1\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.5=h7579374_1\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.24.0=py_0\n",
            "    - ruamel_yaml==0.15.87=py38h7b6447c_1\n",
            "    - setuptools==50.3.1=py38h06a4308_1\n",
            "    - six==1.15.0=py38h06a4308_0\n",
            "    - sqlite==3.33.0=h62c20be_0\n",
            "    - tk==8.6.10=hbc83047_0\n",
            "    - tqdm==4.51.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.25.11=py_0\n",
            "    - wheel==0.35.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.10.14-0\n",
            "  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.3-py38h261ae71_2\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py38h06a4308_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.9.2-py38h06a4308_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.2-py38h03888b9_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-3.2.1-py38h3c74f83_1\n",
            "  idna               pkgs/main/noarch::idna-2.10-py_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1h-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-19.1.0-pyhd3eb1b0_1\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.5-h7579374_1\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  requests           pkgs/main/noarch::requests-2.24.0-py_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py38h7b6447c_1\n",
            "  setuptools         pkgs/main/linux-64::setuptools-50.3.1-py38h06a4308_1\n",
            "  six                pkgs/main/linux-64::six-1.15.0-py38h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.51.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.25.11-py_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.35.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2021.1.19  |       h06a4308_0         121 KB\n",
            "    certifi-2020.12.5          |   py38h06a4308_0         141 KB\n",
            "    cffi-1.14.5                |   py38h261ae71_0         224 KB\n",
            "    chardet-4.0.0              |py38h06a4308_1003         194 KB\n",
            "    cryptography-3.3.1         |   py38h3c74f83_1         567 KB\n",
            "    idna-2.10                  |     pyhd3eb1b0_0          52 KB\n",
            "    openssl-1.1.1j             |       h27cfd23_0         2.5 MB\n",
            "    pip-21.0.1                 |   py38h06a4308_0         1.8 MB\n",
            "    pyopenssl-20.0.1           |     pyhd3eb1b0_1          49 KB\n",
            "    readline-8.1               |       h27cfd23_0         362 KB\n",
            "    requests-2.25.1            |     pyhd3eb1b0_0          52 KB\n",
            "    setuptools-52.0.0          |   py38h06a4308_0         714 KB\n",
            "    tqdm-4.56.0                |     pyhd3eb1b0_0          80 KB\n",
            "    urllib3-1.26.3             |     pyhd3eb1b0_0         105 KB\n",
            "    wheel-0.36.2               |     pyhd3eb1b0_0          33 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         6.9 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                              2020.10.14-0 --> 2021.1.19-h06a4308_0\n",
            "  certifi            pkgs/main/noarch::certifi-2020.6.20-p~ --> pkgs/main/linux-64::certifi-2020.12.5-py38h06a4308_0\n",
            "  cffi                                1.14.3-py38h261ae71_2 --> 1.14.5-py38h261ae71_0\n",
            "  chardet                           3.0.4-py38h06a4308_1003 --> 4.0.0-py38h06a4308_1003\n",
            "  cryptography                         3.2.1-py38h3c74f83_1 --> 3.3.1-py38h3c74f83_1\n",
            "  openssl                                 1.1.1h-h7b6447c_0 --> 1.1.1j-h27cfd23_0\n",
            "  pip                                 20.2.4-py38h06a4308_0 --> 21.0.1-py38h06a4308_0\n",
            "  pyopenssl                             19.1.0-pyhd3eb1b0_1 --> 20.0.1-pyhd3eb1b0_1\n",
            "  readline                                   8.0-h7b6447c_0 --> 8.1-h27cfd23_0\n",
            "  requests                                      2.24.0-py_0 --> 2.25.1-pyhd3eb1b0_0\n",
            "  setuptools                          50.3.1-py38h06a4308_1 --> 52.0.0-py38h06a4308_0\n",
            "  tqdm                                  4.51.0-pyhd3eb1b0_0 --> 4.56.0-pyhd3eb1b0_0\n",
            "  urllib3                                      1.25.11-py_0 --> 1.26.3-pyhd3eb1b0_0\n",
            "  wheel                                 0.35.1-pyhd3eb1b0_0 --> 0.36.2-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  idna                                            2.10-py_0 --> 2.10-pyhd3eb1b0_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pygmt\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n",
            "    _openmp_mutex-4.5          |            1_gnu          22 KB  conda-forge\n",
            "    atk-1.0-2.36.0             |       h3371d22_4         560 KB  conda-forge\n",
            "    boost-cpp-1.74.0           |       hc6e9bd1_2        16.3 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h7f98852_4         484 KB  conda-forge\n",
            "    c-ares-1.17.1              |       h7f98852_1         109 KB  conda-forge\n",
            "    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n",
            "    cairo-1.16.0               |    h7979940_1007         1.5 MB  conda-forge\n",
            "    certifi-2020.12.5          |   py38h578d9bd_1         143 KB  conda-forge\n",
            "    cfitsio-3.470              |       hb418390_7         1.3 MB  conda-forge\n",
            "    cftime-1.4.1               |   py38h5c078b8_0         325 KB  conda-forge\n",
            "    chrpath-0.16               |    h14c3975_1001          29 KB  conda-forge\n",
            "    conda-4.9.2                |   py38h578d9bd_0         3.0 MB  conda-forge\n",
            "    curl-7.75.0                |       h979ede3_0         147 KB  conda-forge\n",
            "    dbus-1.13.6                |       hfdff14a_1         585 KB  conda-forge\n",
            "    dcw-gmt-1.1.4              |             1001        20.2 MB  conda-forge\n",
            "    expat-2.2.10               |       h9c3ff4c_0         164 KB  conda-forge\n",
            "    ffmpeg-4.3.1               |       hca11adc_2        91.9 MB  conda-forge\n",
            "    fftw-3.3.9                 |nompi_h74d3f13_101         6.4 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    hba837de_1004         344 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    freexl-1.0.5               |    h516909a_1002          46 KB  conda-forge\n",
            "    fribidi-1.0.10             |       h36c2ea0_0         112 KB  conda-forge\n",
            "    gdal-3.2.1                 |   py38hc0b2d6b_8         1.5 MB  conda-forge\n",
            "    gdk-pixbuf-2.42.2          |       h0c95a7a_2         611 KB  conda-forge\n",
            "    geos-3.9.1                 |       h9c3ff4c_2         1.1 MB  conda-forge\n",
            "    geotiff-1.6.0              |       hcf90da6_5         296 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    h0b5b191_1005         3.6 MB  conda-forge\n",
            "    ghostscript-9.53.3         |       h58526e2_2        56.7 MB  conda-forge\n",
            "    giflib-5.2.1               |       h36c2ea0_2          77 KB  conda-forge\n",
            "    glib-2.66.7                |       h9c3ff4c_1         443 KB  conda-forge\n",
            "    glib-tools-2.66.7          |       h9c3ff4c_1          85 KB  conda-forge\n",
            "    gmp-6.2.1                  |       h58526e2_0         806 KB  conda-forge\n",
            "    gmt-6.1.1                  |       hbd5eb69_5        30.5 MB  conda-forge\n",
            "    gnuplot-5.4.1              |       hc654d65_1         1.2 MB  conda-forge\n",
            "    gnutls-3.6.13              |       h85f3911_1         2.0 MB  conda-forge\n",
            "    graphicsmagick-1.3.35      |       h2852e03_2         4.2 MB  conda-forge\n",
            "    graphite2-1.3.13           |    h58526e2_1001         102 KB  conda-forge\n",
            "    gshhg-gmt-2.3.7            |             1002        54.6 MB  conda-forge\n",
            "    gst-plugins-base-1.18.3    |       h04508c2_0         2.5 MB  conda-forge\n",
            "    gstreamer-1.18.3           |       h3560a44_0         2.0 MB  conda-forge\n",
            "    gtk2-2.24.33               |       hab0c2f8_0         7.3 MB  conda-forge\n",
            "    harfbuzz-2.7.4             |       h5cf4720_0         1.9 MB  conda-forge\n",
            "    hdf4-4.2.13                |    h10796ff_1004         951 KB  conda-forge\n",
            "    hdf5-1.10.6                |nompi_h6a2412b_1114         3.1 MB  conda-forge\n",
            "    icu-68.1                   |       h58526e2_0        13.0 MB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    json-c-0.15                |       h98cffda_0         274 KB  conda-forge\n",
            "    kealib-1.4.14              |       he4dc956_1         186 KB  conda-forge\n",
            "    krb5-1.17.2                |       h926e7f8_0         1.4 MB  conda-forge\n",
            "    lame-3.100                 |    h7f98852_1001         496 KB  conda-forge\n",
            "    libblas-3.9.0              |       8_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       8_openblas          11 KB  conda-forge\n",
            "    libclang-11.1.0            |default_ha53f305_0        19.2 MB  conda-forge\n",
            "    libcurl-7.75.0             |       hc4aaa36_0         328 KB  conda-forge\n",
            "    libdap4-3.20.6             |       hd7c4107_1        11.4 MB  conda-forge\n",
            "    libev-4.33                 |       h516909a_1         104 KB  conda-forge\n",
            "    libevent-2.1.10            |       hcdb4288_3         1.1 MB  conda-forge\n",
            "    libgcc-ng-9.3.0            |      h2828fa1_18         7.8 MB  conda-forge\n",
            "    libgd-2.3.0                |       h47910db_1         297 KB  conda-forge\n",
            "    libgdal-3.2.1              |       h6636813_8        13.3 MB  conda-forge\n",
            "    libgfortran-ng-9.3.0       |      hff62375_18          22 KB  conda-forge\n",
            "    libgfortran5-9.3.0         |      hff62375_18         2.0 MB  conda-forge\n",
            "    libglib-2.66.7             |       h3e27bee_1         3.0 MB  conda-forge\n",
            "    libgomp-9.3.0              |      h2828fa1_18         376 KB  conda-forge\n",
            "    libiconv-1.16              |       h516909a_0         1.4 MB  conda-forge\n",
            "    libkml-1.3.0               |    h02e6976_1012         590 KB  conda-forge\n",
            "    liblapack-3.9.0            |       8_openblas          11 KB  conda-forge\n",
            "    libllvm11-11.1.0           |       hf817b99_0        29.1 MB  conda-forge\n",
            "    libnetcdf-4.7.4            |nompi_h56d31a8_107         1.3 MB  conda-forge\n",
            "    libnghttp2-1.43.0          |       h812cca2_0         808 KB  conda-forge\n",
            "    libopenblas-0.3.12         |pthreads_h4812303_1         8.9 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libpq-13.1                 |       hfd2b0eb_2         2.7 MB  conda-forge\n",
            "    librttopo-1.1.0            |       h1185371_6         235 KB  conda-forge\n",
            "    libspatialite-5.0.1        |       h20cb978_4         4.4 MB  conda-forge\n",
            "    libssh2-1.9.0              |       hab1572f_5         225 KB  conda-forge\n",
            "    libstdcxx-ng-9.3.0         |      h6de172a_18         4.0 MB  conda-forge\n",
            "    libtiff-4.2.0              |       hdc55705_0         633 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n",
            "    libwebp-1.2.0              |       h3452ae3_0          85 KB  conda-forge\n",
            "    libwebp-base-1.2.0         |       h7f98852_0         808 KB  conda-forge\n",
            "    libxcb-1.13                |    h7f98852_1003         395 KB  conda-forge\n",
            "    libxkbcommon-1.0.3         |       he3ba5ed_0         581 KB  conda-forge\n",
            "    libxml2-2.9.10             |       h72842e0_3         1.3 MB  conda-forge\n",
            "    lz4-c-1.9.3                |       h9c3ff4c_0         179 KB  conda-forge\n",
            "    mysql-common-8.0.23        |       ha770c72_1         1.5 MB  conda-forge\n",
            "    mysql-libs-8.0.23          |       h935591d_1         1.8 MB  conda-forge\n",
            "    netcdf4-1.5.6              |nompi_py38h1cdf482_100         555 KB  conda-forge\n",
            "    nettle-3.6                 |       he412f7d_0         6.5 MB  conda-forge\n",
            "    nspr-4.29                  |       h9c3ff4c_1         232 KB  conda-forge\n",
            "    nss-3.62                   |       hb5efdd6_0         2.1 MB  conda-forge\n",
            "    numpy-1.20.1               |   py38h18fd61f_0         5.8 MB  conda-forge\n",
            "    openh264-2.1.1             |       h780b84a_0         1.5 MB  conda-forge\n",
            "    openjpeg-2.4.0             |       hf7af979_0         525 KB  conda-forge\n",
            "    openssl-1.1.1j             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    packaging-20.9             |     pyh44b312d_0          35 KB  conda-forge\n",
            "    pandas-1.2.3               |   py38h51da96c_0        12.1 MB  conda-forge\n",
            "    pango-1.42.4               |       h69149e4_5         533 KB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pixman-0.40.0              |       h36c2ea0_0         627 KB  conda-forge\n",
            "    poppler-0.89.0             |       h2de54a5_5        15.6 MB  conda-forge\n",
            "    poppler-data-0.4.10        |                0         3.8 MB  conda-forge\n",
            "    postgresql-13.1            |       h6303168_2         5.2 MB  conda-forge\n",
            "    proj-8.0.0                 |       h277dcde_0         3.1 MB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    pygmt-0.3.0                |     pyhd8ed1ab_1         6.4 MB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-3.8.8               |       hdb3f193_4        50.0 MB\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.8             |           1_cp38           4 KB  conda-forge\n",
            "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
            "    qt-5.12.9                  |       hda022c4_4        99.5 MB  conda-forge\n",
            "    sqlite-3.34.0              |       h74cdb3f_0         1.4 MB  conda-forge\n",
            "    tiledb-2.2.4               |       hb9a9e87_1         2.6 MB  conda-forge\n",
            "    tzcode-2021a               |       h7f98852_1          68 KB  conda-forge\n",
            "    tzdata-2021a               |       he74cb21_0         121 KB  conda-forge\n",
            "    x264-1!161.3030            |       h7f98852_0         2.4 MB  conda-forge\n",
            "    xarray-0.17.0              |     pyhd8ed1ab_0         561 KB  conda-forge\n",
            "    xerces-c-3.2.3             |       h9d8b166_2         1.8 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h7f98852_0          58 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    hd9c2040_1000          26 KB  conda-forge\n",
            "    xorg-libx11-1.7.0          |       h7f98852_0         923 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h7f98852_1          54 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h7f98852_1003          32 KB  conda-forge\n",
            "    xorg-libxt-1.2.1           |       h7f98852_2         375 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h7f98852_1002          28 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n",
            "    zstd-1.4.9                 |       ha95c52a_0         431 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       683.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  atk-1.0            conda-forge/linux-64::atk-1.0-2.36.0-h3371d22_4\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-hc6e9bd1_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
            "  c-ares             conda-forge/linux-64::c-ares-1.17.1-h7f98852_1\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h7979940_1007\n",
            "  cfitsio            conda-forge/linux-64::cfitsio-3.470-hb418390_7\n",
            "  cftime             conda-forge/linux-64::cftime-1.4.1-py38h5c078b8_0\n",
            "  chrpath            conda-forge/linux-64::chrpath-0.16-h14c3975_1001\n",
            "  curl               conda-forge/linux-64::curl-7.75.0-h979ede3_0\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-hfdff14a_1\n",
            "  dcw-gmt            conda-forge/linux-64::dcw-gmt-1.1.4-1001\n",
            "  expat              conda-forge/linux-64::expat-2.2.10-h9c3ff4c_0\n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-4.3.1-hca11adc_2\n",
            "  fftw               conda-forge/linux-64::fftw-3.3.9-nompi_h74d3f13_101\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-hba837de_1004\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  freexl             conda-forge/linux-64::freexl-1.0.5-h516909a_1002\n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.10-h36c2ea0_0\n",
            "  gdal               conda-forge/linux-64::gdal-3.2.1-py38hc0b2d6b_8\n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.42.2-h0c95a7a_2\n",
            "  geos               conda-forge/linux-64::geos-3.9.1-h9c3ff4c_2\n",
            "  geotiff            conda-forge/linux-64::geotiff-1.6.0-hcf90da6_5\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
            "  ghostscript        conda-forge/linux-64::ghostscript-9.53.3-h58526e2_2\n",
            "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2\n",
            "  glib               conda-forge/linux-64::glib-2.66.7-h9c3ff4c_1\n",
            "  glib-tools         conda-forge/linux-64::glib-tools-2.66.7-h9c3ff4c_1\n",
            "  gmp                conda-forge/linux-64::gmp-6.2.1-h58526e2_0\n",
            "  gmt                conda-forge/linux-64::gmt-6.1.1-hbd5eb69_5\n",
            "  gnuplot            conda-forge/linux-64::gnuplot-5.4.1-hc654d65_1\n",
            "  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1\n",
            "  graphicsmagick     conda-forge/linux-64::graphicsmagick-1.3.35-h2852e03_2\n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.13-h58526e2_1001\n",
            "  gshhg-gmt          conda-forge/linux-64::gshhg-gmt-2.3.7-1002\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.18.3-h04508c2_0\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.18.3-h3560a44_0\n",
            "  gtk2               conda-forge/linux-64::gtk2-2.24.33-hab0c2f8_0\n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-2.7.4-h5cf4720_0\n",
            "  hdf4               conda-forge/linux-64::hdf4-4.2.13-h10796ff_1004\n",
            "  hdf5               conda-forge/linux-64::hdf5-1.10.6-nompi_h6a2412b_1114\n",
            "  icu                conda-forge/linux-64::icu-68.1-h58526e2_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  json-c             conda-forge/linux-64::json-c-0.15-h98cffda_0\n",
            "  kealib             conda-forge/linux-64::kealib-1.4.14-he4dc956_1\n",
            "  krb5               conda-forge/linux-64::krb5-1.17.2-h926e7f8_0\n",
            "  lame               conda-forge/linux-64::lame-3.100-h7f98852_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-8_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-8_openblas\n",
            "  libclang           conda-forge/linux-64::libclang-11.1.0-default_ha53f305_0\n",
            "  libcurl            conda-forge/linux-64::libcurl-7.75.0-hc4aaa36_0\n",
            "  libdap4            conda-forge/linux-64::libdap4-3.20.6-hd7c4107_1\n",
            "  libev              conda-forge/linux-64::libev-4.33-h516909a_1\n",
            "  libevent           conda-forge/linux-64::libevent-2.1.10-hcdb4288_3\n",
            "  libgd              conda-forge/linux-64::libgd-2.3.0-h47910db_1\n",
            "  libgdal            conda-forge/linux-64::libgdal-3.2.1-h6636813_8\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_18\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_18\n",
            "  libglib            conda-forge/linux-64::libglib-2.66.7-h3e27bee_1\n",
            "  libgomp            conda-forge/linux-64::libgomp-9.3.0-h2828fa1_18\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n",
            "  libkml             conda-forge/linux-64::libkml-1.3.0-h02e6976_1012\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-8_openblas\n",
            "  libllvm11          conda-forge/linux-64::libllvm11-11.1.0-hf817b99_0\n",
            "  libnetcdf          conda-forge/linux-64::libnetcdf-4.7.4-nompi_h56d31a8_107\n",
            "  libnghttp2         conda-forge/linux-64::libnghttp2-1.43.0-h812cca2_0\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.12-pthreads_h4812303_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libpq              conda-forge/linux-64::libpq-13.1-hfd2b0eb_2\n",
            "  librttopo          conda-forge/linux-64::librttopo-1.1.0-h1185371_6\n",
            "  libspatialite      conda-forge/linux-64::libspatialite-5.0.1-h20cb978_4\n",
            "  libssh2            conda-forge/linux-64::libssh2-1.9.0-hab1572f_5\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.2.0-hdc55705_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libwebp            conda-forge/linux-64::libwebp-1.2.0-h3452ae3_0\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.0-h7f98852_0\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1003\n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.0.3-he3ba5ed_0\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h72842e0_3\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_0\n",
            "  mysql-common       conda-forge/linux-64::mysql-common-8.0.23-ha770c72_1\n",
            "  mysql-libs         conda-forge/linux-64::mysql-libs-8.0.23-h935591d_1\n",
            "  netcdf4            conda-forge/linux-64::netcdf4-1.5.6-nompi_py38h1cdf482_100\n",
            "  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0\n",
            "  nspr               conda-forge/linux-64::nspr-4.29-h9c3ff4c_1\n",
            "  nss                conda-forge/linux-64::nss-3.62-hb5efdd6_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.1-py38h18fd61f_0\n",
            "  openh264           conda-forge/linux-64::openh264-2.1.1-h780b84a_0\n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hf7af979_0\n",
            "  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.2.3-py38h51da96c_0\n",
            "  pango              conda-forge/linux-64::pango-1.42.4-h69149e4_5\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.40.0-h36c2ea0_0\n",
            "  poppler            conda-forge/linux-64::poppler-0.89.0-h2de54a5_5\n",
            "  poppler-data       conda-forge/noarch::poppler-data-0.4.10-0\n",
            "  postgresql         conda-forge/linux-64::postgresql-13.1-h6303168_2\n",
            "  proj               conda-forge/linux-64::proj-8.0.0-h277dcde_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  pygmt              conda-forge/noarch::pygmt-0.3.0-pyhd8ed1ab_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.8-1_cp38\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  qt                 conda-forge/linux-64::qt-5.12.9-hda022c4_4\n",
            "  tiledb             conda-forge/linux-64::tiledb-2.2.4-hb9a9e87_1\n",
            "  tzcode             conda-forge/linux-64::tzcode-2021a-h7f98852_1\n",
            "  tzdata             conda-forge/noarch::tzdata-2021a-he74cb21_0\n",
            "  x264               conda-forge/linux-64::x264-1!161.3030-h7f98852_0\n",
            "  xarray             conda-forge/noarch::xarray-0.17.0-pyhd8ed1ab_0\n",
            "  xerces-c           conda-forge/linux-64::xerces-c-3.2.3-h9d8b166_2\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.0-h7f98852_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
            "  xorg-libxt         conda-forge/linux-64::xorg-libxt-1.2.1-h7f98852_2\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.9-ha95c52a_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  certifi            pkgs/main::certifi-2020.12.5-py38h06a~ --> conda-forge::certifi-2020.12.5-py38h578d9bd_1\n",
            "  libgcc-ng           pkgs/main::libgcc-ng-9.1.0-hdf63c60_0 --> conda-forge::libgcc-ng-9.3.0-h2828fa1_18\n",
            "  libstdcxx-ng       pkgs/main::libstdcxx-ng-9.1.0-hdf63c6~ --> conda-forge::libstdcxx-ng-9.3.0-h6de172a_18\n",
            "  python                                   3.8.5-h7579374_1 --> 3.8.8-hdb3f193_4\n",
            "  sqlite                pkgs/main::sqlite-3.33.0-h62c20be_0 --> conda-forge::sqlite-3.34.0-h74cdb3f_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge\n",
            "  ca-certificates    pkgs/main::ca-certificates-2021.1.19-~ --> conda-forge::ca-certificates-2020.12.5-ha878542_0\n",
            "  conda               pkgs/main::conda-4.9.2-py38h06a4308_0 --> conda-forge::conda-4.9.2-py38h578d9bd_0\n",
            "  openssl              pkgs/main::openssl-1.1.1j-h27cfd23_0 --> conda-forge::openssl-1.1.1j-h7f98852_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... \n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCWUXSjqeH57",
        "outputId": "2ebdcf37-1db2-4cd3-e2a7-2a4dc5f0f419"
      },
      "source": [
        "! conda create --name gmt6\n",
        "! conda activate gmt6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: A conda environment already exists at '/usr/local/envs/gmt6'\n",
            "Remove existing environment (y/[n])? y\n",
            "\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/gmt6\n",
            "\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Verifying transaction: / \b\bdone\n",
            "Executing transaction: \\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate gmt6\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYp2guQadw2A",
        "outputId": "f1631c3a-28c8-4a80-b2a0-19a127655eb9"
      },
      "source": [
        "! conda config --prepend channels conda-forge\n",
        "! conda install python=3.9 pygmt pip numpy pandas xarray netcdf4 packaging gmt pytest pytest-mpl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: 'conda-forge' already in 'channels' list, moving to the top\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2PO5nb_e696",
        "outputId": "f1fd0d2a-f085-423c-ee68-0f048de5795f"
      },
      "source": [
        "! conda activate gmt6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntxd4V1PfEYS",
        "outputId": "8f4298cd-9e3b-4f11-9be3-864766f1fa14"
      },
      "source": [
        "!conda create --name pygmt --channel conda-forge pygmt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/pygmt\n",
            "\n",
            "  added / updated specs:\n",
            "    - pygmt\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ld_impl_linux-64-2.35.1    |       hea4e1c9_2         618 KB  conda-forge\n",
            "    libedit-3.1.20191231       |       he28a2e2_2         121 KB  conda-forge\n",
            "    libffi-3.3                 |       h58526e2_2          51 KB  conda-forge\n",
            "    ncurses-6.2                |       h58526e2_4         985 KB  conda-forge\n",
            "    readline-8.0               |       he28a2e2_2         281 KB  conda-forge\n",
            "    tk-8.6.10                  |       h21135ba_1         3.2 MB  conda-forge\n",
            "    wheel-0.36.2               |     pyhd3deb0d_0          31 KB  conda-forge\n",
            "    xz-5.2.5                   |       h516909a_1         343 KB  conda-forge\n",
            "    zlib-1.2.11                |    h516909a_1010         106 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         5.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  atk-1.0            conda-forge/linux-64::atk-1.0-2.36.0-h3371d22_4\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-hc6e9bd1_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
            "  c-ares             conda-forge/linux-64::c-ares-1.17.1-h7f98852_1\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2020.12.5-ha878542_0\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h7979940_1007\n",
            "  certifi            conda-forge/linux-64::certifi-2020.12.5-py39hf3d152e_1\n",
            "  cfitsio            conda-forge/linux-64::cfitsio-3.470-hb418390_7\n",
            "  cftime             conda-forge/linux-64::cftime-1.4.1-py39hce5d2b2_0\n",
            "  chrpath            conda-forge/linux-64::chrpath-0.16-h14c3975_1001\n",
            "  curl               conda-forge/linux-64::curl-7.75.0-h979ede3_0\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-hfdff14a_1\n",
            "  dcw-gmt            conda-forge/linux-64::dcw-gmt-1.1.4-1001\n",
            "  expat              conda-forge/linux-64::expat-2.2.10-h9c3ff4c_0\n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-4.3.1-hca11adc_2\n",
            "  fftw               conda-forge/linux-64::fftw-3.3.9-nompi_h74d3f13_101\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-hba837de_1004\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  freexl             conda-forge/linux-64::freexl-1.0.5-h516909a_1002\n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.10-h36c2ea0_0\n",
            "  gdal               conda-forge/linux-64::gdal-3.2.1-py39h409cc32_8\n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.42.2-h0c95a7a_2\n",
            "  geos               conda-forge/linux-64::geos-3.9.1-h9c3ff4c_2\n",
            "  geotiff            conda-forge/linux-64::geotiff-1.6.0-hcf90da6_5\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
            "  ghostscript        conda-forge/linux-64::ghostscript-9.53.3-h58526e2_2\n",
            "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2\n",
            "  glib               conda-forge/linux-64::glib-2.66.7-h9c3ff4c_1\n",
            "  glib-tools         conda-forge/linux-64::glib-tools-2.66.7-h9c3ff4c_1\n",
            "  gmp                conda-forge/linux-64::gmp-6.2.1-h58526e2_0\n",
            "  gmt                conda-forge/linux-64::gmt-6.1.1-hbd5eb69_5\n",
            "  gnuplot            conda-forge/linux-64::gnuplot-5.4.1-hc654d65_1\n",
            "  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1\n",
            "  graphicsmagick     conda-forge/linux-64::graphicsmagick-1.3.35-h2852e03_2\n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.13-h58526e2_1001\n",
            "  gshhg-gmt          conda-forge/linux-64::gshhg-gmt-2.3.7-1002\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.18.3-h04508c2_0\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.18.3-h3560a44_0\n",
            "  gtk2               conda-forge/linux-64::gtk2-2.24.33-hab0c2f8_0\n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-2.7.4-h5cf4720_0\n",
            "  hdf4               conda-forge/linux-64::hdf4-4.2.13-h10796ff_1004\n",
            "  hdf5               conda-forge/linux-64::hdf5-1.10.6-nompi_h6a2412b_1114\n",
            "  icu                conda-forge/linux-64::icu-68.1-h58526e2_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  json-c             conda-forge/linux-64::json-c-0.15-h98cffda_0\n",
            "  kealib             conda-forge/linux-64::kealib-1.4.14-he4dc956_1\n",
            "  krb5               conda-forge/linux-64::krb5-1.17.2-h926e7f8_0\n",
            "  lame               conda-forge/linux-64::lame-3.100-h7f98852_1001\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.35.1-hea4e1c9_2\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-8_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-8_openblas\n",
            "  libclang           conda-forge/linux-64::libclang-11.1.0-default_ha53f305_0\n",
            "  libcurl            conda-forge/linux-64::libcurl-7.75.0-hc4aaa36_0\n",
            "  libdap4            conda-forge/linux-64::libdap4-3.20.6-hd7c4107_1\n",
            "  libedit            conda-forge/linux-64::libedit-3.1.20191231-he28a2e2_2\n",
            "  libev              conda-forge/linux-64::libev-4.33-h516909a_1\n",
            "  libevent           conda-forge/linux-64::libevent-2.1.10-hcdb4288_3\n",
            "  libffi             conda-forge/linux-64::libffi-3.3-h58526e2_2\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-9.3.0-h2828fa1_18\n",
            "  libgd              conda-forge/linux-64::libgd-2.3.0-h47910db_1\n",
            "  libgdal            conda-forge/linux-64::libgdal-3.2.1-h6636813_8\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_18\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_18\n",
            "  libglib            conda-forge/linux-64::libglib-2.66.7-h3e27bee_1\n",
            "  libgomp            conda-forge/linux-64::libgomp-9.3.0-h2828fa1_18\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n",
            "  libkml             conda-forge/linux-64::libkml-1.3.0-h02e6976_1012\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-8_openblas\n",
            "  libllvm11          conda-forge/linux-64::libllvm11-11.1.0-hf817b99_0\n",
            "  libnetcdf          conda-forge/linux-64::libnetcdf-4.7.4-nompi_h56d31a8_107\n",
            "  libnghttp2         conda-forge/linux-64::libnghttp2-1.43.0-h812cca2_0\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.12-pthreads_h4812303_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libpq              conda-forge/linux-64::libpq-13.1-hfd2b0eb_2\n",
            "  librttopo          conda-forge/linux-64::librttopo-1.1.0-h1185371_6\n",
            "  libspatialite      conda-forge/linux-64::libspatialite-5.0.1-h20cb978_4\n",
            "  libssh2            conda-forge/linux-64::libssh2-1.9.0-hab1572f_5\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-9.3.0-h6de172a_18\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.2.0-hdc55705_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libwebp            conda-forge/linux-64::libwebp-1.2.0-h3452ae3_0\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.0-h7f98852_0\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1003\n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.0.3-he3ba5ed_0\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h72842e0_3\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_0\n",
            "  mysql-common       conda-forge/linux-64::mysql-common-8.0.23-ha770c72_1\n",
            "  mysql-libs         conda-forge/linux-64::mysql-libs-8.0.23-h935591d_1\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.2-h58526e2_4\n",
            "  netcdf4            conda-forge/linux-64::netcdf4-1.5.6-nompi_py39h36800e2_100\n",
            "  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0\n",
            "  nspr               conda-forge/linux-64::nspr-4.29-h9c3ff4c_1\n",
            "  nss                conda-forge/linux-64::nss-3.62-hb5efdd6_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.1-py39hdbf815f_0\n",
            "  openh264           conda-forge/linux-64::openh264-2.1.1-h780b84a_0\n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hf7af979_0\n",
            "  openssl            conda-forge/linux-64::openssl-1.1.1j-h7f98852_0\n",
            "  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.2.3-py39hde0f152_0\n",
            "  pango              conda-forge/linux-64::pango-1.42.4-h69149e4_5\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pip                conda-forge/noarch::pip-21.0.1-pyhd8ed1ab_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.40.0-h36c2ea0_0\n",
            "  poppler            conda-forge/linux-64::poppler-0.89.0-h2de54a5_5\n",
            "  poppler-data       conda-forge/noarch::poppler-data-0.4.10-0\n",
            "  postgresql         conda-forge/linux-64::postgresql-13.1-h6303168_2\n",
            "  proj               conda-forge/linux-64::proj-8.0.0-h277dcde_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  pygmt              conda-forge/noarch::pygmt-0.3.0-pyhd8ed1ab_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python             conda-forge/linux-64::python-3.9.2-hffdb5ce_0_cpython\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.9-1_cp39\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  qt                 conda-forge/linux-64::qt-5.12.9-hda022c4_4\n",
            "  readline           conda-forge/linux-64::readline-8.0-he28a2e2_2\n",
            "  setuptools         conda-forge/linux-64::setuptools-49.6.0-py39hf3d152e_3\n",
            "  six                conda-forge/noarch::six-1.15.0-pyh9f0ad1d_0\n",
            "  sqlite             conda-forge/linux-64::sqlite-3.34.0-h74cdb3f_0\n",
            "  tiledb             conda-forge/linux-64::tiledb-2.2.4-hb9a9e87_1\n",
            "  tk                 conda-forge/linux-64::tk-8.6.10-h21135ba_1\n",
            "  tzcode             conda-forge/linux-64::tzcode-2021a-h7f98852_1\n",
            "  tzdata             conda-forge/noarch::tzdata-2021a-he74cb21_0\n",
            "  wheel              conda-forge/noarch::wheel-0.36.2-pyhd3deb0d_0\n",
            "  x264               conda-forge/linux-64::x264-1!161.3030-h7f98852_0\n",
            "  xarray             conda-forge/noarch::xarray-0.17.0-pyhd8ed1ab_0\n",
            "  xerces-c           conda-forge/linux-64::xerces-c-3.2.3-h9d8b166_2\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.0-h7f98852_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
            "  xorg-libxt         conda-forge/linux-64::xorg-libxt-1.2.1-h7f98852_2\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
            "  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_1\n",
            "  zlib               conda-forge/linux-64::zlib-1.2.11-h516909a_1010\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.9-ha95c52a_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "ld_impl_linux-64-2.3 | 618 KB    | : 100% 1.0/1 [00:00<00:00,  5.08it/s]\n",
            "zlib-1.2.11          | 106 KB    | : 100% 1.0/1 [00:00<00:00, 20.47it/s]\n",
            "tk-8.6.10            | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.92it/s]\n",
            "libedit-3.1.20191231 | 121 KB    | : 100% 1.0/1 [00:00<00:00, 22.90it/s]\n",
            "ncurses-6.2          | 985 KB    | : 100% 1.0/1 [00:00<00:00,  3.07it/s]\n",
            "libffi-3.3           | 51 KB     | : 100% 1.0/1 [00:00<00:00, 28.22it/s]\n",
            "readline-8.0         | 281 KB    | : 100% 1.0/1 [00:00<00:00, 14.36it/s]\n",
            "wheel-0.36.2         | 31 KB     | : 100% 1.0/1 [00:00<00:00, 31.04it/s]\n",
            "xz-5.2.5             | 343 KB    | : 100% 1.0/1 [00:00<00:00, 11.78it/s]\n",
            "Preparing transaction: - \b\b\\ y\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate pygmt\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qkkG9qKf1ZC",
        "outputId": "7530323e-accc-49e4-d02e-f40602f02369"
      },
      "source": [
        "!conda activate pygmt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "sUEIDl5Rf8qX",
        "outputId": "c4068ce0-80e1-4c83-970c-6abc93073e60"
      },
      "source": [
        "import "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5974fc3f40b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpygmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpygmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygmt'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}